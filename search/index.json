[{"content":"动手学深度学习-4.5. 权重衰减 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 %matplotlib inline import torch from torch import nn from d2l import torch as d2l n_train, n_test, num_inputs, batch_size = 20, 100, 200, 5 true_w, true_b = torch.ones((num_inputs, 1)) * 0.01, 0.05 # d2l.synthetic_data会生成生成满足𝑦=𝑋𝑤+𝑏+𝜖的数据，返回 (features, labels) 两个张量 train_data = d2l.synthetic_data(true_w, true_b, n_train) # d2l.load_array((features, labels), batch_size, is_train)用 TensorDataset + DataLoader 打包成小批量数据迭代器。 # 得到的train_iter 每次迭代给一批 (X, y)，形状分别是 (batch_size, 200) 和 (batch_size, 1) train_iter = d2l.load_array(train_data, batch_size) test_data = d2l.synthetic_data(true_w, true_b, n_test) test_iter = d2l.load_array(test_data, batch_size, is_train=False) 1 2 3 4 5 6 def init_params(): w = torch.normal(0, 1, size=(num_inputs, 1), requires_grad=True) b = torch.zeros(1, requires_grad=True) return [w, b] def l2_penalty(w): return torch.sum(w.pow(2)) / 2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def train(lambd): w, b = init_params() # 此处的loss是不带L2惩罚项的损失函数 net, loss = lambda X: d2l.linreg(X, w, b), d2l.squared_loss num_epochs, lr = 100, 0.003 animator = d2l.Animator(xlabel=\u0026#39;epochs\u0026#39;, ylabel=\u0026#39;loss\u0026#39;, yscale=\u0026#39;log\u0026#39;, xlim=[5, num_epochs], legend=[\u0026#39;train\u0026#39;, \u0026#39;test\u0026#39;]) for epoch in range(num_epochs): for X, y in train_iter: # 增加了L2范数惩罚项， # 广播机制使l2_penalty(w)成为一个长度为batch_size的向量 l = loss(net(X), y) + lambd * l2_penalty(w) l.sum().backward() d2l.sgd([w, b], lr, batch_size) if (epoch + 1) % 5 == 0: animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss), d2l.evaluate_loss(net, test_iter, loss))) print(\u0026#39;w的L2范数是：\u0026#39;, torch.norm(w).item()) 1 2 # 不用正则化 train(lambd=0) 1 2 # 适中正则化 train(lambd=3) 1 2 # 强正则化 train(lambd=10) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # 使用框架自带的方法实现L2正则化 def train_concise(wd): net = nn.Sequential(nn.Linear(num_inputs, 1)) for param in net.parameters(): param.data.normal_() loss = nn.MSELoss(reduction=\u0026#39;none\u0026#39;) num_epochs, lr = 100, 0.003 # net[0].weight → 设置 weight_decay=wd，表示在更新时自动加上 L2 正则项梯度 # 偏置参数没有衰减 trainer = torch.optim.SGD([ {\u0026#34;params\u0026#34;:net[0].weight,\u0026#39;weight_decay\u0026#39;: wd}, {\u0026#34;params\u0026#34;:net[0].bias}], lr=lr) animator = d2l.Animator(xlabel=\u0026#39;epochs\u0026#39;, ylabel=\u0026#39;loss\u0026#39;, yscale=\u0026#39;log\u0026#39;, xlim=[5, num_epochs], legend=[\u0026#39;train\u0026#39;, \u0026#39;test\u0026#39;]) for epoch in range(num_epochs): for X, y in train_iter: trainer.zero_grad() # 清除上一步的梯度 # loss(...) 计算逐样本的 MSE 损失（不含正则项，L2 正则化由优化器在梯度更新时自动添加） l = loss(net(X), y) # net(X)前向计算预测值 # .mean()：转成标量（批内平均），这样 backward() 才能运行 # .backward()：反向传播，计算纯数据误差的梯度； # 之后在 trainer.step() 阶段，优化器会在梯度中额外加上 wd * w（实现 L2 正则化的效果） l.mean().backward() trainer.step() # 按 SGD 规则更新参数 if (epoch + 1) % 5 == 0: animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss), d2l.evaluate_loss(net, test_iter, loss))) print(\u0026#39;w的L2范数：\u0026#39;, net[0].weight.norm().item()) 1 train_concise(0) 1 train_concise(3) 1 train_concise(10) 问题总结 问1：w.pow(2)具体是怎么计算的，w不是一个矩阵吗 w 在这里是一个形状 (200, 1) 的二维张量（可以看作 200×1 矩阵），w.pow(2) 是 逐元素平方 运算，不是矩阵乘法平方。\n即对 w 中的每一个元素 w_i_j 单独平方，得到的新张量的形状和 w 完全一样。\n问2：train()函数中lambd这个参数有什么意义 lambd 就是 L2 正则化的系数（也叫权重衰减系数、regularization coefficient），它直接控制了正则项在总损失中所占的比重。\ntrain()函数中定义的损失函数形式为：\n$$ λ 越大 → 正则化惩罚项越重要 → 模型会更强烈地压缩权重的大小 → 权重的 L2 范数∥𝑤∥_2会变小\\\\ λ 越小 → 正则化的作用越弱 → 更接近普通的最小二乘回归。 $$ 问3： w 的 L2 范数在这里到底意味着什么 w 是一个 (200×1) 的列向量，代表 200 个输入特征的权重系数。\nL2 范数（Euclidean norm）就是把它看作一个点，测量它离原点有多远： $$ ∥w∥_2 = \\sqrt{w_1^2 +w_2^2 +⋯+w_{200}^2} $$ 这就像测量一个 200 维空间里的向量的“长度”（它是权重向量的长度，在数学上就是到原点的距离）。\n值越大 → 权重整体幅度越大，说明模型更“激进”，对输入变化反应可能更敏感，过拟合风险更高。\n值越小 → 权重整体幅度越小，模型更平滑，对新数据可能泛化更好（但也可能欠拟合）。\n","date":"2025-08-11T11:44:25+08:00","image":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-4.5.-%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F/index_hu_ee6b10762b6f6f6e.png","permalink":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-4.5.-%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F/","title":"动手学深度学习-4.5. 权重衰减"},{"content":"动手学深度学习-4.3. 多层感知机的简洁实现 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 import torch from torch import nn from d2l import torch as d2l net = nn.Sequential(nn.Flatten(), nn.Linear(784, 256), nn.ReLU(), nn.Linear(256, 10)) # 遍历神经网络的各层的函数，若为线性层，则按照均值为0、标准差为0.01的正态分布初始化权重 def init_weights(m): if type(m) == nn.Linear: nn.init.normal_(m.weight, std=0.01) # apply(fn) 会把传入的函数 fn 应用到当前 Module 以及它的所有子模块（submodules）上，递归调用 net.apply(init_weights); batch_size, lr, num_epochs = 256, 0.1, 10 loss = nn.CrossEntropyLoss(reduction=\u0026#39;none\u0026#39;) trainer = torch.optim.SGD(net.parameters(), lr=lr) train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) # 累加器 class Accumulator: \u0026#34;\u0026#34;\u0026#34;在n个变量上累加\u0026#34;\u0026#34;\u0026#34; def __init__(self, n): self.data = [0.0] * n def add(self, *args): self.data = [a + float(b) for a, b in zip(self.data, args)] def reset(self): self.data = [0.0] * len(self.data) def __getitem__(self, idx): return self.data[idx] # 准确率 def accuracy(y_hat, y): # y_hat 是 logits 或 概率都可以；二维时按类别维取 argmax if y_hat.ndim \u0026gt; 1 and y_hat.shape[1] \u0026gt; 1: y_hat = y_hat.argmax(dim=1) return (y_hat.type(y.dtype) == y).float().mean().item() # 在数据集上评估准确率 def evaluate_accuracy(net, data_iter): if isinstance(net, torch.nn.Module): net.eval() metric = Accumulator(2) # [预测正确数, 总样本数] with torch.no_grad(): for X, y in data_iter: metric.add((net(X).argmax(dim=1) == y).sum(), y.numel()) return metric[0] / metric[1] # 训练一轮 def train_epoch_ch3(net, train_iter, loss, updater): if isinstance(net, torch.nn.Module): net.train() metric = Accumulator(3) # [损失和, 预测正确数, 样本总数] for X, y in train_iter: y_hat = net(X) l = loss(y_hat, y) # 这里兼容 CrossEntropyLoss(reduction=\u0026#39;none\u0026#39;) if isinstance(updater, torch.optim.Optimizer): updater.zero_grad() l.mean().backward() updater.step() else: l.sum().backward() updater(X.shape[0]) metric.add(l.sum(), (y_hat.argmax(dim=1) == y).sum(), y.numel()) return metric[0] / metric[2], metric[1] / metric[2] # 训练主流程（含简单打印） def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater): for epoch in range(num_epochs): train_loss, train_acc = train_epoch_ch3(net, train_iter, loss, updater) test_acc = evaluate_accuracy(net, test_iter) print(f\u0026#39;epoch {epoch+1}: \u0026#39; f\u0026#39;loss {train_loss:.4f}, train acc {train_acc:.3f}, test acc {test_acc:.3f}\u0026#39;) train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) 运行结果 ","date":"2025-08-10T10:44:25+08:00","image":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-4.3.-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/index_hu_8280d38d476c6339.png","permalink":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-4.3.-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/","title":"动手学深度学习-4.3. 多层感知机的简洁实现"},{"content":"动手学深度学习-4.2. 多层感知机的从零开始实现 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 import torch from torch import nn from d2l import torch as d2l batch_size = 256 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) num_inputs, num_outputs, num_hiddens = 784, 10, 256 W1 = nn.Parameter(torch.randn( num_inputs, num_hiddens, requires_grad=True) * 0.01) b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True)) W2 = nn.Parameter(torch.randn( num_hiddens, num_outputs, requires_grad=True) * 0.01) b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True)) params = [W1, b1, W2, b2] def relu(X): # 创建一个形状，dtype，device与X完全相同的全0张量 # dtype 决定了张量里单个元素的数值类型和精度 # device 表示张量存储和计算所在的硬件设备 a = torch.zeros_like(X) return torch.max(X, a) def net(X): X = X.reshape((-1, num_inputs)) # @代表矩阵乘法 H = relu(X@W1 + b1) return (H@W2 + b2) # 默认对最后一层进行softmax处理 loss = nn.CrossEntropyLoss(reduction=\u0026#39;none\u0026#39;) num_epochs, lr = 10, 0.1 updater = torch.optim.SGD(params, lr=lr) # 累加器 class Accumulator: \u0026#34;\u0026#34;\u0026#34;在n个变量上累加\u0026#34;\u0026#34;\u0026#34; def __init__(self, n): self.data = [0.0] * n def add(self, *args): self.data = [a + float(b) for a, b in zip(self.data, args)] def reset(self): self.data = [0.0] * len(self.data) def __getitem__(self, idx): return self.data[idx] # 准确率 def accuracy(y_hat, y): # y_hat 是 logits 或 概率都可以；二维时按类别维取 argmax if y_hat.ndim \u0026gt; 1 and y_hat.shape[1] \u0026gt; 1: y_hat = y_hat.argmax(dim=1) return (y_hat.type(y.dtype) == y).float().mean().item() # 在数据集上评估准确率 def evaluate_accuracy(net, data_iter): if isinstance(net, torch.nn.Module): net.eval() metric = Accumulator(2) # [预测正确数, 总样本数] with torch.no_grad(): for X, y in data_iter: metric.add((net(X).argmax(dim=1) == y).sum(), y.numel()) return metric[0] / metric[1] # 训练一轮 def train_epoch_ch3(net, train_iter, loss, updater): if isinstance(net, torch.nn.Module): net.train() metric = Accumulator(3) # [损失和, 预测正确数, 样本总数] for X, y in train_iter: y_hat = net(X) l = loss(y_hat, y) # 这里兼容 CrossEntropyLoss(reduction=\u0026#39;none\u0026#39;) if isinstance(updater, torch.optim.Optimizer): updater.zero_grad() l.mean().backward() updater.step() else: l.sum().backward() updater(X.shape[0]) metric.add(l.sum(), (y_hat.argmax(dim=1) == y).sum(), y.numel()) return metric[0] / metric[2], metric[1] / metric[2] # 训练主流程（含简单打印） def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater): for epoch in range(num_epochs): train_loss, train_acc = train_epoch_ch3(net, train_iter, loss, updater) test_acc = evaluate_accuracy(net, test_iter) print(f\u0026#39;epoch {epoch+1}: \u0026#39; f\u0026#39;loss {train_loss:.4f}, train acc {train_acc:.3f}, test acc {test_acc:.3f}\u0026#39;) train_ch3(net, train_iter, test_iter, loss, num_epochs, updater) def predict_ch3(net, test_iter, n=6): #@save \u0026#34;\u0026#34;\u0026#34;随机选n张图片，展示真实和预测标签\u0026#34;\u0026#34;\u0026#34; for X, y in test_iter: break # 取第一个batch trues = d2l.get_fashion_mnist_labels(y) # 真实标签（转文本） preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1)) # 预测标签（转文本） # 合并“真实+预测”作为标题 titles = [true +\u0026#39;\\n\u0026#39; + pred for true, pred in zip(trues, preds)] # 可视化前n张图片及标签 d2l.show_images( X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n]) predict_ch3(net, test_iter) 运行结果 ","date":"2025-08-09T10:44:25+08:00","image":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-4.2.-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0/index_hu_6952dd3e586c4f57.png","permalink":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-4.2.-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0/","title":"动手学深度学习-4.2. 多层感知机的从零开始实现"},{"content":"动手学深度学习-3.7. softmax回归的简洁实现 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 import torch from torch import nn from d2l import torch as d2l batch_size = 256 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) # 想要查看train_iter的形状不能train_iter.shape # 因为train_iter 是 PyTorch 的 DataLoader 对象，本质上是个可迭代器（iterator），并不是一个张量（torch.Tensor），所以它没有 .shape 属性 # iter():把一个可迭代对象（比如 train_iter、list、tuple）变成一个迭代器对象，迭代器对象是可以用 next() 一次一次取数据的 # next():从迭代器对象里取下一个元素，每调用一次 next()，迭代器就往前走一步，直到取完所有元素，如果再调用 next()，会报 StopIteration 错误 # 每次取一个batch X, y = next(iter(train_iter)) print(X.shape) # 图片批次的形状 print(y.shape) # 标签批次的形状 # PyTorch不会隐式地调整输入的形状。因此， # nn.Linear 全连接层要求输入是二维所以要在之前加入展平层，将(batchsize, 1, 28, 28)的输入形状转换为(batchsize,784) net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10)) def init_weights(m): if type(m) == nn.Linear: nn.init.normal_(m.weight, std=0.01) net.apply(init_weights); loss = nn.CrossEntropyLoss(reduction=\u0026#39;none\u0026#39;) trainer = torch.optim.SGD(net.parameters(), lr=0.1) num_epochs = 10 # d2l包里没有train_ch3方法 # d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) # 累加器 class Accumulator: \u0026#34;\u0026#34;\u0026#34;在n个变量上累加\u0026#34;\u0026#34;\u0026#34; def __init__(self, n): self.data = [0.0] * n def add(self, *args): self.data = [a + float(b) for a, b in zip(self.data, args)] def reset(self): self.data = [0.0] * len(self.data) def __getitem__(self, idx): return self.data[idx] # 准确率 def accuracy(y_hat, y): # y_hat 是 logits 或 概率都可以；二维时按类别维取 argmax if y_hat.ndim \u0026gt; 1 and y_hat.shape[1] \u0026gt; 1: y_hat = y_hat.argmax(dim=1) return (y_hat.type(y.dtype) == y).float().mean().item() # 在数据集上评估准确率 def evaluate_accuracy(net, data_iter): if isinstance(net, torch.nn.Module): net.eval() metric = Accumulator(2) # [预测正确数, 总样本数] with torch.no_grad(): for X, y in data_iter: metric.add((net(X).argmax(dim=1) == y).sum(), y.numel()) return metric[0] / metric[1] # 训练一轮 def train_epoch_ch3(net, train_iter, loss, updater): if isinstance(net, torch.nn.Module): net.train() metric = Accumulator(3) # [损失和, 预测正确数, 样本总数] for X, y in train_iter: y_hat = net(X) l = loss(y_hat, y) # 这里兼容 CrossEntropyLoss(reduction=\u0026#39;none\u0026#39;) if isinstance(updater, torch.optim.Optimizer): updater.zero_grad() l.mean().backward() updater.step() else: l.sum().backward() updater(X.shape[0]) metric.add(l.sum(), (y_hat.argmax(dim=1) == y).sum(), y.numel()) return metric[0] / metric[2], metric[1] / metric[2] # 训练主流程（含简单打印） def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater): for epoch in range(num_epochs): train_loss, train_acc = train_epoch_ch3(net, train_iter, loss, updater) test_acc = evaluate_accuracy(net, test_iter) print(f\u0026#39;epoch {epoch+1}: \u0026#39; f\u0026#39;loss {train_loss:.4f}, train acc {train_acc:.3f}, test acc {test_acc:.3f}\u0026#39;) train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) 运行结果 ","date":"2025-08-08T10:44:25+08:00","image":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-3.7.-softmax%E5%9B%9E%E5%BD%92%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/index_hu_4ec5be606bec4201.jpg","permalink":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-3.7.-softmax%E5%9B%9E%E5%BD%92%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/","title":"动手学深度学习-3.7. softmax回归的简洁实现"},{"content":"动手学深度学习-3.6. softmax回归的从零开始实现 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 import torch from IPython import display from d2l import torch as d2l # 图像预处理流水线（load_data_fashion_mnist用到） from torchvision import transforms # 数据集加载（load_data_fashion_mnist用到FashionMNIST） import torchvision # DataLoader等数据批处理工具（load_data_fashion_mnist等用到） from torch.utils import data # 选择数据加载线程数 def get_dataloader_workers(): \u0026#34;\u0026#34;\u0026#34;使用多少个进程来读取数据。win建议1，linux建议4\u0026#34;\u0026#34;\u0026#34; return 4 # 数据加载与预处理 def load_data_fashion_mnist(batch_size, resize=None): #@save # 1. 创建处理操作列表（先转张量，必要时resize插在前面） # trans是一个长度为1的列表，只有ToTensor()操作的这一个元素 trans = [transforms.ToTensor()] # 如果有resize操作，将其插入trans列表中的首位 if resize: trans.insert(0, transforms.Resize(resize)) # 2. 组装成复合变换器 trans = transforms.Compose(trans) # 3. 加载训练集和测试集（图片将自动做上述预处理） mnist_train = torchvision.datasets.FashionMNIST( root=\u0026#34;../data\u0026#34;, train=True, transform=trans, download=True) mnist_test = torchvision.datasets.FashionMNIST( root=\u0026#34;../data\u0026#34;, train=False, transform=trans, download=True) # 4. 用DataLoader分批加载（训练集打乱，测试集不打乱） return (data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=get_dataloader_workers()), data.DataLoader(mnist_test, batch_size, shuffle=False, num_workers=get_dataloader_workers())) # 获取训练、测试集数据批量迭代器 batch_size = 256 train_iter, test_iter = load_data_fashion_mnist(batch_size) # 参数初始化 # 28*28像素=784，输入特征长度 num_inputs = 784 # 10类（每个图片属于0~9之一） num_outputs = 10 # 权重参数（正态分布初始化），形状[784,10] W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True) b = torch.zeros(num_outputs, requires_grad=True) # 偏置参数 # Softmax函数 def softmax(X): X_exp = torch.exp(X) # 对每个元素做指数运算 partition = X_exp.sum(1, keepdim=True) # 每行求和得到分母（列向量），保留二维结构 return X_exp / partition # 用广播机制，每个元素除以对应分母，得到概率 # 线性分类器（前向传播） def net(X): # 1. X展平成二维(batch,784)；2. 乘以权重再加偏置；3. 送入softmax得到概率 return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b) # 交叉熵损失函数 def cross_entropy(y_hat, y): # 取每个样本真实类别的概率，取对数后取负，得到损失 return - torch.log(y_hat[range(len(y_hat)), y]) # 计算准确率的函数 def accuracy(y_hat, y): #@save \u0026#34;\u0026#34;\u0026#34;计算预测正确的数量\u0026#34;\u0026#34;\u0026#34; # 如果y_hat是概率分布，先转成预测类别（取最大概率的下标） if len(y_hat.shape) \u0026gt; 1 and y_hat.shape[1] \u0026gt; 1: y_hat = y_hat.argmax(axis=1) # 比较预测类别和真实标签，得到布尔型（True/False） cmp = y_hat.type(y.dtype) == y return float(cmp.type(y.dtype).sum()) # 统计预测正确个数 # 在完整数据集上评估准确率 def evaluate_accuracy(net, data_iter): \u0026#34;\u0026#34;\u0026#34;计算在指定数据集上模型的精度\u0026#34;\u0026#34;\u0026#34; if isinstance(net, torch.nn.Module): net.eval() # 如果是标准PyTorch模型，切换到评估模式 metric = Accumulator(2) # [预测对数，总样本数] with torch.no_grad(): # 禁用梯度，节省内存和计算 for X, y in data_iter: metric.add(accuracy(net(X), y), y.numel()) return metric[0] / metric[1] # 返回准确率 # 多变量累加器工具类 class Accumulator: #@save \u0026#34;\u0026#34;\u0026#34;在n个变量上累加\u0026#34;\u0026#34;\u0026#34; def __init__(self, n): self.data = [0.0] * n # 初始化长度为n的列表 def add(self, *args): self.data = [a + float(b) for a, b in zip(self.data, args)] # 位置对齐相加 def reset(self): self.data = [0.0] * len(self.data) # __getitem__是python内置的魔法方法 def __getitem__(self, idx): return self.data[idx] # 支持索引读取（obj[idx]） # 示例：评估当前网络在测试集上的准确率 evaluate_accuracy(net, test_iter) # 训练一轮epoch def train_epoch_ch3(net, train_iter, loss, updater): #@save \u0026#34;\u0026#34;\u0026#34;训练模型一个迭代周期\u0026#34;\u0026#34;\u0026#34; if isinstance(net, torch.nn.Module): net.train() # 如果是标准模型，切换到训练模式 metric = Accumulator(3) # [损失和，预测对数，样本总数] for X, y in train_iter: # 前向传播，计算预测和损失 y_hat = net(X) l = loss(y_hat, y) # 反向传播与参数更新（两种情况） if isinstance(updater, torch.optim.Optimizer): updater.zero_grad() l.mean().backward() updater.step() else: l.sum().backward() updater(X.shape[0]) # 累加统计量 metric.add(float(l.sum()), accuracy(y_hat, y), y.numel()) # 返回平均损失和准确率 return metric[0] / metric[2], metric[1] / metric[2] # 训练过程动画可视化类 class Animator: #@save \u0026#34;\u0026#34;\u0026#34;在动画中绘制数据（支持多曲线）\u0026#34;\u0026#34;\u0026#34; def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None, ylim=None, xscale=\u0026#39;linear\u0026#39;, yscale=\u0026#39;linear\u0026#39;, fmts=(\u0026#39;-\u0026#39;, \u0026#39;m--\u0026#39;, \u0026#39;g-.\u0026#39;, \u0026#39;r:\u0026#39;), nrows=1, ncols=1, figsize=(3.5, 2.5)): if legend is None: legend = [] d2l.use_svg_display() self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize) if nrows * ncols == 1: self.axes = [self.axes, ] # 传递配置参数，便于后续重绘 self.config_axes = lambda: d2l.set_axes( self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend) self.X, self.Y, self.fmts = None, None, fmts def add(self, x, y): # 增量式添加多个数据点到曲线 if not hasattr(y, \u0026#34;__len__\u0026#34;): y = [y] n = len(y) if not hasattr(x, \u0026#34;__len__\u0026#34;): x = [x] * n if not self.X: self.X = [[] for _ in range(n)] if not self.Y: self.Y = [[] for _ in range(n)] for i, (a, b) in enumerate(zip(x, y)): if a is not None and b is not None: self.X[i].append(a) self.Y[i].append(b) self.axes[0].cla() # 清除旧内容 for x, y, fmt in zip(self.X, self.Y, self.fmts): self.axes[0].plot(x, y, fmt) self.config_axes() display.display(self.fig) display.clear_output(wait=True) # 总控训练主流程函数 def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater): #@save \u0026#34;\u0026#34;\u0026#34;训练主控流程：每epoch训练/评估/可视化\u0026#34;\u0026#34;\u0026#34; animator = Animator(xlabel=\u0026#39;epoch\u0026#39;, xlim=[1, num_epochs], ylim=[0.3, 0.9], legend=[\u0026#39;train loss\u0026#39;, \u0026#39;train acc\u0026#39;, \u0026#39;test acc\u0026#39;]) for epoch in range(num_epochs): train_metrics = train_epoch_ch3(net, train_iter, loss, updater) # 训练一轮 test_acc = evaluate_accuracy(net, test_iter) # 测试集评估 animator.add(epoch + 1, train_metrics + (test_acc,)) # 画曲线 train_loss, train_acc = train_metrics # 自动检测模型效果 assert train_loss \u0026lt; 0.5, train_loss assert train_acc \u0026lt;= 1 and train_acc \u0026gt; 0.7, train_acc assert test_acc \u0026lt;= 1 and test_acc \u0026gt; 0.7, test_acc # 学习率 lr = 0.1 def updater(batch_size): # 用d2l的SGD优化器 return d2l.sgd([W, b], lr, batch_size) num_epochs = 10 # 开始训练并动态可视化 train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater) # 可视化预测效果的函数 def predict_ch3(net, test_iter, n=6): #@save \u0026#34;\u0026#34;\u0026#34;随机选n张图片，展示真实和预测标签\u0026#34;\u0026#34;\u0026#34; for X, y in test_iter: break # 取第一个batch trues = d2l.get_fashion_mnist_labels(y) # 真实标签（转文本） preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1)) # 预测标签（转文本） # 合并“真实+预测”作为标题 titles = [true +\u0026#39;\\n\u0026#39; + pred for true, pred in zip(trues, preds)] # 可视化前n张图片及标签 d2l.show_images( X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n]) # 运行预测和可视化 predict_ch3(net, test_iter) 运行结果 ","date":"2025-08-07T14:44:25+08:00","image":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-3.6.-softmax%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0/index_hu_b78a2939fab46f81.jpg","permalink":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-3.6.-softmax%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0/","title":"动手学深度学习-3.6. softmax回归的从零开始实现"},{"content":"动手学深度学习-3.3. 线性回归的简洁实现 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 import numpy as np import torch from torch.utils import data from d2l import torch as d2l true_w = torch.tensor([2, -3.4]) true_b = 4.2 # 使用d2l包自带的功能生成符合y=wx+b的带噪声的数据X和y features, labels = d2l.synthetic_data(true_w, true_b, 1000) def load_array(data_arrays, batch_size, is_train=True): #@save \u0026#34;\u0026#34;\u0026#34;构造一个PyTorch数据迭代器\u0026#34;\u0026#34;\u0026#34; # TensorDataset 是一个数据集类型，将多个张量（tensor）打包成一个可索引的数据集 # *data_arrays 的 * 是 Python 的“拆包”语法 # 如果 data_arrays 是 (features, labels)，那么 *data_arrays 就会展开成两个参数：TensorDataset(features, labels) dataset = data.TensorDataset(*data_arrays) # DataLoader返回可迭代对象 # 返回的 DataLoader 支持小批量、自动乱序（若 is_train=True）以及高效迭代 return data.DataLoader(dataset, batch_size, shuffle=is_train) batch_size = 10 data_iter = load_array((features, labels), batch_size) # 打印的是一个batch的特征和标签，不是一对（是一组） print(\u0026#34;取出一个batch组大小的(X,y)数据对：\u0026#34;,next(iter(data_iter))) # nn是神经网络的缩写 from torch import nn # nn 是 PyTorch 的神经网络模块 # nn.Linear(2, 1)表示全连接层，输入为2维，输出为1维 net = nn.Sequential(nn.Linear(2, 1)) # net[0]：相当于取 nn.Sequential 里的第一个层（这里就是 nn.Linear(2, 1)） # .weight 表示第一层的权重张量，.data 直接访问权重数据本身（通常只在初始化或调试用） net[0].weight.data.normal_(0, 0.01) net[0].bias.data.fill_(0) loss = nn.MSELoss() trainer = torch.optim.SGD(net.parameters(), lr=0.03) num_epochs = 3 for epoch in range(num_epochs): for X, y in data_iter: # net(X)就是神经网络预测的结果 l = loss(net(X) ,y) # zero_grad是清除累积梯度 trainer.zero_grad() # l.backward是反向传播自动求导 l.backward() # step是用梯度更新参数 trainer.step() l = loss(net(features), labels) print(f\u0026#39;epoch {epoch + 1}, loss {l:f}\u0026#39;) w = net[0].weight.data print(\u0026#39;w的估计误差：\u0026#39;, true_w - w.reshape(true_w.shape)) b = net[0].bias.data print(\u0026#39;b的估计误差：\u0026#39;, true_b - b) 运行结果 ","date":"2025-08-06T14:44:25+08:00","image":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-3.3.-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/index_hu_8cab70e00d02ff6a.jpg","permalink":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-3.3.-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/","title":"动手学深度学习-3.3. 线性回归的简洁实现"},{"content":"动手学深度学习-3.2. 线性回归的从零开始实现 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 %matplotlib inline import random import torch from d2l import torch as d2l # 生成X和带噪声的y def synthetic_data(w, b, num_examples): #@save \u0026#34;\u0026#34;\u0026#34;生成y=Xw+b+噪声\u0026#34;\u0026#34;\u0026#34; # 生成x形状为[num_examples, len(w)]，本次为(1000，2)的服从标准正态分布的数据 X = torch.normal(0, 1, (num_examples, len(w))) # matmul()实现矩阵和向量的乘法 y = torch.matmul(X, w) + b y += torch.normal(0, 0.01, y.shape) # y.reshape((-1, 1))表示将y转换为一列形式的数据，-1代表自动根据别的维度调整，确保y为二维列向量，便于与模型输出做减法 return X, y.reshape((-1, 1)) # 初始化w和b的真值 true_w = torch.tensor([2, -3.4]) true_b = 4.2 # features即为上述函数生成的X，形状为(1000,2) # lables形状为(1000,1) features, labels = synthetic_data(true_w, true_b, 1000) # 查看features和labels的第一个值 print(\u0026#39;features和labels的样子:\u0026#39;) print(\u0026#39;features:\u0026#39;, features[0],\u0026#39;\\nlabel:\u0026#39;, labels[0]) # 画出所有样本第2个特征与标签的散点图，观察特征和标签的线性关系 # features[:, (1)].detach().numpy()中：detach()表示从张量中分离出来数据（后续不参与反向传播），.numpy()表示matplotlib只能接受numpy数据 d2l.set_figsize() d2l.plt.scatter(features[:, (1)].detach().numpy(), labels.detach().numpy(), 1); # 分批次取出数据的函数 def data_iter(batch_size, features, labels): num_examples = len(features) indices = list(range(num_examples)) # 这些样本是随机读取的，没有特定的顺序 random.shuffle(indices) for i in range(0, num_examples, batch_size): batch_indices = torch.tensor( indices[i: min(i + batch_size, num_examples)]) # yield 让函数变为生成器，每次返回一批数据，支持按需逐批读取所有样本，节省内存 yield features[batch_indices], labels[batch_indices] batch_size = 10 # 查看第一组数据的样子 for X, y in data_iter(batch_size, features, labels): print(\u0026#34;第一组数据的样子：\u0026#34;) print(X, \u0026#39;\\n\u0026#39;, y) break # 初始化w和b为随机数 w = torch.normal(0, 0.01, size=(2,1), requires_grad=True) b = torch.zeros(1, requires_grad=True) def linreg(X, w, b): #@save \u0026#34;\u0026#34;\u0026#34;线性回归模型\u0026#34;\u0026#34;\u0026#34; return torch.matmul(X, w) + b def squared_loss(y_hat, y): #@save \u0026#34;\u0026#34;\u0026#34;均方损失\u0026#34;\u0026#34;\u0026#34; return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2 def sgd(params, lr, batch_size): #@save \u0026#34;\u0026#34;\u0026#34;小批量随机梯度下降\u0026#34;\u0026#34;\u0026#34; with torch.no_grad(): for param in params: param -= lr * param.grad / batch_size # 每次手动梯度清零（因为每次param.grad属性是 PyTorch 张量的一个成员，专门用来存放当前参数的梯度值） # 每次调用 .backward()，PyTorch 会把算出来的梯度加到参数已有的 .grad 上，而不是覆盖 # 如果不清零，每个 batch、每个 mini-batch 的梯度就会一直累加下去，最后更新参数时会把之前的全部加上，导致训练发散或完全错误。 param.grad.zero_() lr = 0.03 # 训练轮数 num_epochs = 3 # 选用线性模型（上面自己写好的函数） net = linreg # 选用均方误差（上面自己写好的函数） loss = squared_loss for epoch in range(num_epochs): for X, y in data_iter(batch_size, features, labels): l = loss(net(X, w, b), y) # X和y的小批量损失 # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，并以此计算关于[w,b]的梯度（因为backward要求标量作为目标） # 同时也对应了sgd()函数中的：param -= lr * param.grad / batch_size的“/ batch_size”，即先求和再除以批大小 # 完全也可以sgd()函数不除以batch_size，然后此处sum()改为mean() l.sum().backward() sgd([w, b], lr, batch_size) # 使用参数的梯度更新参数 with torch.no_grad(): train_l = loss(net(features, w, b), labels) print(f\u0026#39;epoch {epoch + 1}, loss {float(train_l.mean()):f}\u0026#39;) print(f\u0026#39;w的估计误差: {true_w - w.reshape(true_w.shape)}\u0026#39;) print(f\u0026#39;b的估计误差: {true_b - b}\u0026#39;) 运行结果 ","date":"2025-08-06T10:34:25+08:00","image":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-3.2.-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0/index_hu_82f287125b34054e.jpg","permalink":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-3.2.-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0/","title":"动手学深度学习-3.2. 线性回归的从零开始实现"},{"content":"创建一个深度学习虚拟环境（包含d2l包） Step1 创建一个名为“d2l_env”的虚拟环境并激活（推荐 Python 3.9，兼容性最佳）：\n1 conda create -n d2l_env python=3.9 1 conda activate d2l_env Step2 使用pip安装pytorch（最新版的pytorch已经不支持conda安装，故采用pip）：\n1 pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 Step3 使用conda安装常见相关依赖\n1 conda install matplotlib pandas jupyter ipykernel Step4 使用pip安装指定版本的d2l包：\n1 pip install d2l==1.0.2 Step5 将这个虚拟环境加入jupyter notebook内核：\n1 python -m ipykernel install --user --name d2l_env --display-name \u0026#34;Python (d2l_env)\u0026#34; ","date":"2025-08-05T14:44:25+08:00","image":"https://example.com/p/%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E5%8C%85%E5%90%ABd2l%E5%8C%85/index_hu_8485bb27c6ba89e1.jpg","permalink":"https://example.com/p/%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E5%8C%85%E5%90%ABd2l%E5%8C%85/","title":"创建一个深度学习虚拟环境（包含d2l包）"},{"content":"线性回归解析解的推导 问题形式化 我们要做的是： 首先给定一组数据 $$ (X,y)\\quad其中X∈R^{n×d}，y∈R^n $$要拟合一个线性模型 $$ y=Xw+b $$ 找到使预测和真实值之间均方误差最小的w和b。\n其次，把每个样本的特征后面加上一列全是1的列，这样就可以把b作为w的一部分处理了。\n所以，如果原始 X 是 n×d 矩阵，我们构造 $$ {X} = [X \\quad \\mathbf{1}] $$其中 1是 n×1 的全1列向量。 此时参数 $$ ~\\tilde{w} 为(d+1) \\times 1向量，最后一个元素就是b $$ 写出目标函数 线性回归的目标是最小化残差平方和（MSE）： $$ L(\\tilde{w}) = \\| y - \\tilde{X}\\tilde{w} \\|^2 $$ 将其写成矩阵相乘的形式： $$ L(w)=∥y−Xw∥^2=(y−Xw) ^⊤(y−Xw) $$ 展开目标函数为： $$ L(w)=y^⊤y−2y^⊤Xw+w^⊤X^⊤Xw $$ 其中： $$ 𝑦^⊤𝑦y^⊤y 是常数项 $$$$ −2𝑦^⊤𝑋𝑤−2y^⊤Xw 是一次项 $$$$ w^⊤X^⊤Xw 是二次项 $$ 解出解析解 现在来对每一项分别求导： $$ y^\\top y：跟w无关，导数是0 $$$$ -2y^\\top Xw：对w求导，就是-2X^\\top y $$$$ w^\\top X^\\top Xw ：对w求导，就是 2X^\\top X w $$ 这样，整个损失函数对w的导数是： $$ \\frac{\\partial L}{\\partial w} = 0 - 2X^\\top y + 2X^\\top X w\\\\= 2X^\\top X w - 2X^\\top y $$ 零其为0，得 $$ X^⊤Xw=X^⊤y $$ 两边左乘 $$ (𝑋^⊤𝑋)^{−1} $$ 得到 $$ w=(X^⊤X)^{−1}X^⊤y $$ 附 矩阵相乘展开： $$ (a−b)^⊤(a−b)=a^⊤a−a^⊤b−b^⊤a+b^⊤b\\\\因为𝑎^⊤𝑏和𝑏^⊤𝑎是标量（它们互为转置，结果相同），所以上面中间两项可以合并为：\\\\𝑎⊤𝑎−2𝑎⊤𝑏+𝑏⊤𝑏 $$ 矩阵求导基础： $$ \\frac{\\partial}{\\partial w}(w^\\top A w) = 2Aw\\quad（其中 A 是对称矩阵） $$$$ \\frac{\\partial}{\\partial w}(b^\\top w) = b\\quad（b 是和 w 维度相同的向量） $$","date":"2025-08-04T14:44:25+08:00","image":"https://example.com/p/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E8%A7%A3%E6%9E%90%E8%A7%A3%E7%9A%84%E6%8E%A8%E5%AF%BC/index_hu_17c525d58159b80.png","permalink":"https://example.com/p/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E8%A7%A3%E6%9E%90%E8%A7%A3%E7%9A%84%E6%8E%A8%E5%AF%BC/","title":"线性回归解析解的推导"},{"content":"Bellman-Ford算法原理及Python实现 算法简介 Bellman-Ford算法主要用于求解有向图的单源最短路径问题，与迪杰斯特拉算法不同，他可以处理带有负权值的图，并且可以检测图中是否有负权环（负权环指的是从源点到源点的一个环，并且环上权重和为负数）。\n算法原理 ​\t它的基本思想是松弛（Relaxation）操作。松弛是指对于每一条边（u，v），如果从源点到顶点 u 的最短路径距离已知，并且从源点到顶点 v 的距离可以通过经过顶点 u 的路径来更新为一个更小的值，那么就更新顶点 v 的当前最短路径距离。\n​\t算法重复进行松弛操作，对于图中的每一条边都进行检查，尝试更新顶点的最短路径估计值。这个过程需要进行 |V| - 1 次（|V| 是图中顶点的数量），因为在最坏情况下，一个顶点的最短路径可能需要经过所有其他顶点。\n​\t因此算法的时间复杂度为 O（|V|・|E|），其中 |V| 是顶点数，|E| 是边数。\n算法流程 步骤1：初始化 将源点的最短路径距离设为 0，其他所有顶点的最短路径距离设为无穷大。\n步骤2：反复进行松弛操作 对于每一条边（u，v），在 |V| - 1 次迭代中，如果当前顶点 u 的最短路径距离加上边（u，v）的权重小于顶点 v 当前记录的最短路径距离，则更新顶点 v 的最短路径距离。\n步骤3：检测是否存在负权回路 在完成 |V| - 1 次松弛操作后，再对所有边进行一次检查。如果还能松弛，说明图中存在从源点可达的负权回路，此时最短路径不存在（因为可以无限绕负权回路来降低路径权重）。\nPython实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 class Edge: def __init__(self, src, dest, weight): self.src = src self.dest = dest self.weight = weight def bellman_ford(vertices, edges, src): # 初始化距离数组，距离源点的距离为无穷大 dist = [float(\u0026#39;inf\u0026#39;)] * (vertices + 1) dist[src] = 0 # 源点到自身的距离为 0 # 进行 vertices-1 次松弛操作 for _ in range(vertices - 1): updated = False for edge in edges: u = edge.src v = edge.dest weight = edge.weight if dist[u] != float(\u0026#39;inf\u0026#39;) and dist[v] \u0026gt; dist[u] + weight: dist[v] = dist[u] + weight updated = True if not updated: break # 如果没有边可以松弛，提前退出 # 检测是否存在负权回路 has_negative_cycle = False for edge in edges: u = edge.src v = edge.dest weight = edge.weight if dist[u] != float(\u0026#39;inf\u0026#39;) and dist[v] \u0026gt; dist[u] + weight: has_negative_cycle = True break return dist, has_negative_cycle 输入与输出 输入为图的邻接矩阵，其中 graph[i][j] 表示从节点 i 到节点 j 的边的权重。如果节点之间没有直接的边，则用一个足够大的值（如 max）表示不可达。\n输出为 path 数组，其中 path[i] 表示从起点到节点 i 的最短路径中，到达节点 i 的前一个节点的索引。如果节点不可达，则 path[i] 为 -1\n若想通过path数组得到从起点到某个节点k的路径，可由如下代码实现：\n1 2 3 4 5 6 7 8 9 10 def get_path(path, start_index, target_index): if path[target_index] == -1: return \u0026#34;没有路径可达\u0026#34; path_list = [] while target_index != start_index: path_list.append(target_index) target_index = path[target_index] path_list.append(start_index) path_list.reverse() return path_list 代码测试 主程序测试代码为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 if __name__ == \u0026#34;__main__\u0026#34;: # 图1的顶点数为 5 vertices1 = 5 # 图1的边集合 edges1 = [ Edge(1, 2, 4), Edge(1, 3, 2), Edge(2, 3, 5), Edge(2, 4, 3), Edge(3, 2, -3), Edge(3, 5, 7), Edge(4, 5, 1), Edge(5, 1, 8) ] # 源点为 1 src1 = 1 distances1, has_negative_cycle1 = bellman_ford(vertices1, edges1, src1) print(\u0026#34;图1示例：无负权环图\u0026#34;) if has_negative_cycle1: print(\u0026#34;图中存在负权回路\u0026#34;) else: print(\u0026#34;源点为\u0026#34;, src1, \u0026#34;的最短距离为:\u0026#34;) for i in range(1, vertices1 + 1): print(\u0026#34;到顶点\u0026#34;, i, \u0026#34;的距离为:\u0026#34;, distances1[i]) #-------------------------------------分割线----------------------------------------------- # 图2的顶点数为 3 vertices2 = 3 edges2 = [ Edge(1, 2, 1), Edge(2, 3, 2), Edge(3, 1, -4) # 这条边形成一个负权环 ] src2 = 1 distances2, has_negative_cycle2 = bellman_ford(vertices2, edges2, src2) print(\u0026#34;图2示例：有负权环图\u0026#34;) if has_negative_cycle2: print(\u0026#34;图中存在负权回路\u0026#34;) else: print(\u0026#34;源点为\u0026#34;, src2, \u0026#34;的最短距离为:\u0026#34;) for i in range(1, vertices2 + 1): print(\u0026#34;到顶点\u0026#34;, i, \u0026#34;的距离为:\u0026#34;, distances2[i]) 运行结果为：\n1 2 3 4 5 6 7 8 9 10 11 E:\\BLOG_article\\Bellman-Ford\\.venv\\Scripts\\python.exe E:\\BLOG_article\\Bellman-Ford\\Bellman-Ford.py 图1示例：无负权环图 源点为 1 的最短距离为: 到顶点 1 的距离为: 0 到顶点 2 的距离为: -1 到顶点 3 的距离为: 2 到顶点 4 的距离为: 2 到顶点 5 的距离为: 3 图2示例：有负权环图 图中存在负权回路 完整代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 class Edge: def __init__(self, src, dest, weight): self.src = src self.dest = dest self.weight = weight def bellman_ford(vertices, edges, src): # 初始化距离数组，距离源点的距离为无穷大 dist = [float(\u0026#39;inf\u0026#39;)] * (vertices + 1) dist[src] = 0 # 源点到自身的距离为 0 # 进行 vertices-1 次松弛操作 for _ in range(vertices - 1): updated = False for edge in edges: u = edge.src v = edge.dest weight = edge.weight if dist[u] != float(\u0026#39;inf\u0026#39;) and dist[v] \u0026gt; dist[u] + weight: dist[v] = dist[u] + weight updated = True if not updated: break # 如果没有边可以松弛，提前退出 # 检测是否存在负权回路 has_negative_cycle = False for edge in edges: u = edge.src v = edge.dest weight = edge.weight if dist[u] != float(\u0026#39;inf\u0026#39;) and dist[v] \u0026gt; dist[u] + weight: has_negative_cycle = True break return dist, has_negative_cycle if __name__ == \u0026#34;__main__\u0026#34;: # 图1的顶点数为 5 vertices1 = 5 # 图1的边集合 edges1 = [ Edge(1, 2, 4), Edge(1, 3, 2), Edge(2, 3, 5), Edge(2, 4, 3), Edge(3, 2, -3), Edge(3, 5, 7), Edge(4, 5, 1), Edge(5, 1, 8) ] # 源点为 1 src1 = 1 distances1, has_negative_cycle1 = bellman_ford(vertices1, edges1, src1) print(\u0026#34;图1示例：无负权环图\u0026#34;) if has_negative_cycle1: print(\u0026#34;图中存在负权回路\u0026#34;) else: print(\u0026#34;源点为\u0026#34;, src1, \u0026#34;的最短距离为:\u0026#34;) for i in range(1, vertices1 + 1): print(\u0026#34;到顶点\u0026#34;, i, \u0026#34;的距离为:\u0026#34;, distances1[i]) #-------------------------------------分割线----------------------------------------------- # 图2的顶点数为 3 vertices2 = 3 edges2 = [ Edge(1, 2, 1), Edge(2, 3, 2), Edge(3, 1, -4) # 这条边形成一个负权环 ] src2 = 1 distances2, has_negative_cycle2 = bellman_ford(vertices2, edges2, src2) print(\u0026#34;图2示例：有负权环图\u0026#34;) if has_negative_cycle2: print(\u0026#34;图中存在负权回路\u0026#34;) else: print(\u0026#34;源点为\u0026#34;, src2, \u0026#34;的最短距离为:\u0026#34;) for i in range(1, vertices2 + 1): print(\u0026#34;到顶点\u0026#34;, i, \u0026#34;的距离为:\u0026#34;, distances2[i]) ","date":"2025-04-26T14:44:25+08:00","image":"https://example.com/p/bellman-ford%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%8F%8Apython%E5%AE%9E%E7%8E%B0/index_hu_446bb884ffc0e559.png","permalink":"https://example.com/p/bellman-ford%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%8F%8Apython%E5%AE%9E%E7%8E%B0/","title":"Bellman-Ford算法原理及Python实现"},{"content":"A*算法原理及Python实现 算法简介 A*算法是一种用于求解最短路径问题的启发式搜索算法，广泛应用于机器人路径规划、游戏地图寻路等场景。与 Dijkstra 算法不同，A* 算法结合了实际路径代价和启发式估计，从而能更高效地找到从起点到终点的最优路径。\n算法原理 A*算法基于以下评价函数进行节点选择：\n1 f(n) = g(n) + h(n) g(n)：从起点到当前节点 n 的实际路径代价 h(n)：从当前节点 n 到目标节点的启发式估计（通常使用曼哈顿距离） f(n)：总代价函数，表示当前路径的优劣程度 通过优先扩展 f(n) 最小的节点，A*算法在保证最优性的同时提高了搜索效率。\n曼哈顿距离 A*算法中常用的启发函数之一是曼哈顿距离（Manhattan Distance），适用于只能沿网格上下左右移动的情况。\n它的计算方式为：\n1 2 复制编辑 h(n) = |x₁ - x₂| + |y₁ - y₂| 其中 (x₁, y₁) 是当前节点的坐标，(x₂, y₂) 是目标节点的坐标。\n这种距离计算方式类似在城市街区中沿街道走路，不能穿墙或斜着走，故称为“曼哈顿”——得名于纽约曼哈顿的棋盘格街道布局。\n算法流程 步骤1：初始化 初始化三个核心数组：\ng数组：记录从起点到当前节点的最小代价，初始全部为 ∞，起点为 0 h数组：记录当前节点到目标节点的启发式估值 f数组：记录总代价，f = g + h open_list：优先队列（小顶堆），用于选择当前代价最小的节点 closed_list：已访问节点集合，避免重复扩展 parent字典：记录每个节点的前驱节点 步骤2：选择f值最小的节点 从 open_list 中取出 f(n) 最小的节点，作为当前处理节点。\n步骤3：判断是否到达目标节点 若当前节点为目标节点，则说明路径已找到，调用 seek_path 方法回溯路径。\n步骤4：扩展邻居节点 获取四个方向的可通行邻居节点（上下左右） 对每个邻居，计算新的 g、h、f 值 若该路径更优，则更新邻居节点的代价信息并加入 open_list Python实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 import heapq import matplotlib.pyplot as plt import numpy as np class AStar: def __init__(self, grid, start, goal): self.grid = grid self.start = start self.goal = goal self.rows = len(grid) self.cols = len(grid[0]) self.open_list = [] self.closed_list = set() self.f = np.full((self.rows, self.cols), np.inf) self.g = np.full((self.rows, self.cols), np.inf) self.h = np.full((self.rows, self.cols), 0) self.parent = {} def seek_heuristic(self, x, y): return abs(self.goal[0] - x) + abs(self.goal[1] - y) def seek_neighborhood(self, x, y): directions = [(0, 1), (0, -1), (1, 0), (-1, 0)] neighbors = [] for dx, dy in directions: if 0 \u0026lt;= x + dx \u0026lt; self.rows and 0 \u0026lt;= y + dy \u0026lt; self.cols and self.grid[x + dx][y + dy] == 0: neighbors.append((x + dx, y + dy)) return neighbors def run(self): self.g[self.start[0], self.start[1]] = 0 self.h[self.start[0], self.start[1]] = self.seek_heuristic(*self.start) self.f[self.start[0], self.start[1]] = self.g[self.start[0], self.start[1]] + self.h[self.start[0], self.start[1]] heapq.heappush(self.open_list, (self.f[self.start[0], self.start[1]], self.start)) while self.open_list: _, current_node = heapq.heappop(self.open_list) if current_node == self.goal: return self.seek_path() self.closed_list.add(current_node) for neighbor in self.seek_neighborhood(*current_node): if neighbor in self.closed_list: continue current_g = self.g[current_node[0], current_node[1]] + 1 if neighbor not in self.parent or current_g \u0026lt; self.g[neighbor[0], neighbor[1]]: self.parent[neighbor] = current_node self.g[neighbor[0], neighbor[1]] = current_g self.h[neighbor[0], neighbor[1]] = self.seek_heuristic(*neighbor) self.f[neighbor[0], neighbor[1]] = self.g[neighbor[0], neighbor[1]] + self.h[neighbor[0], neighbor[1]] if neighbor not in [node[1] for node in self.open_list]: heapq.heappush(self.open_list, (self.f[neighbor[0], neighbor[1]], neighbor)) return None def seek_path(self): path = [] current_node = self.goal while current_node != self.start: path.append(current_node) current_node = self.parent[current_node] path.append(self.start) path.reverse() return path 可视化路径 1 2 3 4 5 6 7 8 9 10 def plot_path(grid, path): plt.figure(figsize=(8, 8)) plt.imshow(grid, cmap=\u0026#39;Greys\u0026#39;, origin=\u0026#39;lower\u0026#39;) path_x, path_y = zip(*path) plt.plot(path_y, path_x, color=\u0026#39;r\u0026#39;, linewidth=2, marker=\u0026#39;o\u0026#39;) plt.scatter(path_y[0], path_x[0], color=\u0026#39;g\u0026#39;, s=100, label=\u0026#39;Start\u0026#39;) plt.scatter(path_y[-1], path_x[-1], color=\u0026#39;b\u0026#39;, s=100, label=\u0026#39;Goal\u0026#39;) plt.legend() plt.title(\u0026#34;A* Pathfinding\u0026#34;) plt.show() 代码测试 主程序测试代码为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 if __name__ == \u0026#34;__main__\u0026#34;: grid = [ [0, 0, 0, 0, 0], [1, 1, 1, 1, 0], [0, 0, 0, 0, 0], [0, 1, 1, 1, 0], [0, 0, 0, 0, 0] ] start = (0, 0) goal = (4, 4) astar = AStar(grid, start, goal) path = astar.run() if path: print(\u0026#34;路径为：\u0026#34;, path) plot_path(grid, path) else: print(\u0026#34;未找到路径\u0026#34;) 运行结果为：\n1 路径为： [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 4), (2, 4), (2, 3), (2, 2), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3), (4, 4)] 完整代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 import heapq import matplotlib.pyplot as plt import numpy as np class AStar: def __init__(self, grid, start, goal): self.grid=grid self.start=start self.goal=goal self.rows=len(grid) self.cols=len(grid[0]) self.open_list=[] self.closed_list=set() self.f=np.full((self.rows,self.cols),np.inf) self.g=np.full((self.rows,self.cols),np.inf) self.h=np.full((self.rows,self.cols),0) self.parent={} def seek_heuristic(self,x,y): return abs(self.goal[0]-x)+abs(self.goal[1]-y) def seek_neighborhood(self,x,y): directions=[(0,1),(0,-1),(1,0),(-1,0)] neighbors=[] for dx,dy in directions: if 0\u0026lt;=x+dx\u0026lt;self.rows and 0\u0026lt;=y+dy\u0026lt;self.cols and self.grid[x+dx][y+dy]==0: neighbors.append((x+dx,y+dy)) return neighbors def run(self): # 初始化起点 self.g[self.start[0], self.start[1]] = 0 self.h[self.start[0], self.start[1]] = self.seek_heuristic(self.start[0], self.start[1]) self.f[self.start[0], self.start[1]] = self.g[self.start[0], self.start[1]]+self.h[self.start[0], self.start[1]] heapq.heappush(self.open_list,(self.f[self.start[0], self.start[1]],self.start)) while self.open_list: _,current_node=heapq.heappop(self.open_list) if current_node==self.goal: return self.seek_path() self.closed_list.add(current_node) for neighbor in self.seek_neighborhood(current_node[0],current_node[1]): if neighbor in self.closed_list: continue current_g=self.g[current_node[0],current_node[1]] + 1 if neighbor not in self.parent or current_g\u0026lt;self.g[neighbor[0],neighbor[1]]: self.parent[neighbor]=current_node self.g[neighbor[0],neighbor[1]] = current_g self.h[neighbor[0],neighbor[1]] = self.seek_heuristic(neighbor[0],neighbor[1]) self.f[neighbor[0],neighbor[1]] = self.g[neighbor[0],neighbor[1]] + self.h[neighbor[0],neighbor[1]] if neighbor not in [node[1] for node in self.open_list]: heapq.heappush(self.open_list,(self.f[neighbor[0],neighbor[1]],neighbor)) return None def seek_path(self): path=[] current_node=self.goal while current_node!=self.start: path.append(current_node) current_node=self.parent[current_node] path.append(self.start) path.reverse() return path def plot_path(grid,path): plt.figure(figsize=(8, 8)) plt.imshow(grid, cmap=\u0026#39;Greys\u0026#39;, origin=\u0026#39;lower\u0026#39;) path_x, path_y = zip(*path) plt.plot(path_y, path_x, color=\u0026#39;r\u0026#39;, linewidth=2, marker=\u0026#39;o\u0026#39;) plt.scatter(path_y[0], path_x[0], color=\u0026#39;g\u0026#39;, s=100, label=\u0026#39;Start\u0026#39;) plt.scatter(path_y[-1], path_x[-1], color=\u0026#39;b\u0026#39;, s=100, label=\u0026#39;Goal\u0026#39;) plt.legend() plt.title(\u0026#34;A* Pathfinding\u0026#34;) plt.show() # 测试 if __name__ == \u0026#34;__main__\u0026#34;: grid = [ [0, 0, 0, 0, 0], [1, 1, 1, 1, 0], [0, 0, 0, 0, 0], [0, 1, 1, 1, 0], [0, 0, 0, 0, 0] ] start = (0, 0) goal = (4, 4) astar = AStar(grid, start, goal) path = astar.run() if path: print(\u0026#34;Path found:\u0026#34;, path) plot_path(grid, path) else: print(\u0026#34;No path found\u0026#34;) ","date":"2025-04-22T14:44:25+08:00","image":"https://example.com/p/a%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%8F%8Apython%E5%AE%9E%E7%8E%B0/index_hu_1b349549350c032d.jpg","permalink":"https://example.com/p/a%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%8F%8Apython%E5%AE%9E%E7%8E%B0/","title":"A*算法原理及Python实现"},{"content":"迪杰斯特拉算法原理及Python实现 算法简介 迪杰斯特拉（Dijkstra）算法主要用于求解没有负值的有向图的单源最短路径问题。\n算法原理 算法基于贪心策略，其核心思想是通过逐步扩展已知最短路径的集合来找到从起点到所有其他节点的最短路径。\n算法流程 步骤1：初始化 初始化cost数组，path数组和visited数组\ncost数组 对于cost数组，初始全部设置为最大值，起点节点设置为0\n1 cost数组：cost[i]表示从start_index到i号元素的最小花费 path数组 对于path数组，初始全部设置为-1，表示不可达，起点节点设置为起点节点的位置\n1 path数组：path[i]表示从start_index到i号元素的最短路径中，到达i号元素的前一个元素索引为path[i]（即想要以最小花费到达i号元素，需要通过path[i]号元素） visited数组 对于visited数组，初始全部设置为0，起点节点设置为1\n1 visited数组：visited[i]表示i号元素是否被访问过（visited[i]==1表示已经找到了最优路径） 步骤2：找到下一个“最优节点” “最优节点”指的是从当前节点到其他节点中代价最小的节点，这个“最优节点”也会作为下一次迭代的“当前节点”\n步骤3：更新visited数组 将找到的最优节点设置成“已访问”状态，即将其设置为“当前节点”\n步骤4：更新“最优节点附近节点的数据” 访问所有还未被访问的节点，若从当前节点“到此节点的代价更小，则更新cost数组和path数组\nPython实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def dijkstra(graph,start_index,max): # 初始化cost,path,visited数组 # cost数组：cost[i]表示从start_index到i号元素的最小花费 cost=[max]*len(graph) cost[start_index] = 0 # path数组：path[i]表示从start_index到i号元素的最短路径中，到达i号元素的前一个元素索引为path[i]（即想要以最小花费到达i号元素，需要通过path[i]号元素） path = [-1] * len(graph) path[start_index] = start_index # visited数组：visited[i]表示i号元素是否被访问过（已经找到了最优路径） visited=[0]*len(graph) visited[start_index]=1 for i in range(len(graph)): if(visited[i]==0): cost[i]=graph[start_index][i] # path[i]=-1表示不可达 path[i]=(start_index if(cost[i]\u0026lt;max) else -1) # 主体代码 for i in range(1,len(graph)): cur_index=-1 min_cost=max # 找到下一步代价最小的节点 for j in range(len(graph)): if(visited[j]==0): if(cost[j]\u0026lt;min_cost): min_cost=cost[j] cur_index=j # 如果没有找到可访问的节点，退出循环 if cur_index==-1: break # 标记下一步代价最小的节点为已访问的节点（当前节点） visited[cur_index]=1 # 依据找到的下一步代价最小的节点cur_index更新其附近一圈的节点数据 for k in range(len(graph)): if(visited[k]==0): if(cost[cur_index]+graph[cur_index][k]\u0026lt;cost[k]): cost[k]=cost[cur_index]+graph[cur_index][k] path[k]=cur_index return path 输入与输出 输入为图的邻接矩阵，其中 graph[i][j] 表示从节点 i 到节点 j 的边的权重。如果节点之间没有直接的边，则用一个足够大的值（如 max）表示不可达。\n输出为 path 数组，其中 path[i] 表示从起点到节点 i 的最短路径中，到达节点 i 的前一个节点的索引。如果节点不可达，则 path[i] 为 -1\n若想通过path数组得到从起点到某个节点k的路径，可由如下代码实现：\n1 2 3 4 5 6 7 8 9 10 def get_path(path, start_index, target_index): if path[target_index] == -1: return \u0026#34;没有路径可达\u0026#34; path_list = [] while target_index != start_index: path_list.append(target_index) target_index = path[target_index] path_list.append(start_index) path_list.reverse() return path_list 代码测试 主程序测试代码为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 if __name__==\u0026#34;__main__\u0026#34;: max=2**31-1 graph=[ [max, max, 10, max, 30, 100], [max, max, 5, max, max, max], [max, max, max, 50, max, max], [max, max, max, max, max, 10], [max, max, max, 20, max, 60], [max, max, max, max, max, max], ] result=dijkstra(graph,0,max) print(\u0026#34;最短路径的前驱节点数组为：\u0026#34;,result) target_index = 5 path_to_target = get_path(result, 0, target_index) print(f\u0026#34;从起点到目标节点 {target_index} 的路径为：\u0026#34;, path_to_target) 运行结果为：\n1 2 3 E:\\BLOG_article\\Dijkstra\\.venv\\Scripts\\python.exe E:\\BLOG_article\\Dijkstra\\Dijkstra.py 最短路径的前驱节点数组为： [0, -1, 0, 4, 0, 3] 从起点到目标节点 5 的路径为： [0, 4, 3, 5] 完整代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 def dijkstra(graph,start_index,max): # 初始化cost,path,visited数组 # cost数组：cost[i]表示从start_index到i号元素的最小花费 cost=[max]*len(graph) cost[start_index] = 0 # path数组：path[i]表示从start_index到i号元素的最短路径中，到达i号元素的前一个元素索引为path[i]（即想要以最小花费到达i号元素，需要通过path[i]号元素） path = [-1] * len(graph) path[start_index] = start_index # visited数组：visited[i]表示i号元素是否被访问过（已经找到了最优路径） visited=[0]*len(graph) visited[start_index]=1 for i in range(len(graph)): if(visited[i]==0): cost[i]=graph[start_index][i] # path[i]=-1表示不可达 path[i]=(start_index if(cost[i]\u0026lt;max) else -1) # 主体代码 for i in range(1,len(graph)): cur_index=-1 min_cost=max # 找到下一步代价最小的节点 for j in range(len(graph)): if(visited[j]==0): if(cost[j]\u0026lt;min_cost): min_cost=cost[j] cur_index=j # 如果没有找到可访问的节点，退出循环 if cur_index==-1: break # 标记下一步代价最小的节点为已访问的节点 visited[cur_index]=1 # 依据找到的下一步代价最小的节点cur_index更新其附近一圈的节点数据 for k in range(len(graph)): if(visited[k]==0): if(cost[cur_index]+graph[cur_index][k]\u0026lt;cost[k]): cost[k]=cost[cur_index]+graph[cur_index][k] path[k]=cur_index return path def get_path(path, start_index, target_index): if path[target_index] == -1: return \u0026#34;No path exists\u0026#34; path_list = [] while target_index != start_index: path_list.append(target_index) target_index = path[target_index] path_list.append(start_index) path_list.reverse() return path_list if __name__==\u0026#34;__main__\u0026#34;: max=2**31-1 graph=[ [max, max, 10, max, 30, 100], [max, max, 5, max, max, max], [max, max, max, 50, max, max], [max, max, max, max, max, 10], [max, max, max, 20, max, 60], [max, max, max, max, max, max], ] result=dijkstra(graph,0,max) print(\u0026#34;最短路径的前驱节点数组为：\u0026#34;,result) target_index = 5 path_to_target = get_path(result, 0, target_index) print(f\u0026#34;从起点到目标节点 {target_index} 的路径为：\u0026#34;, path_to_target) ","date":"2025-04-13T14:44:25+08:00","image":"https://example.com/p/dijkstra%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%8F%8Apython%E5%AE%9E%E7%8E%B0/index_hu_edd18e5053fe4098.png","permalink":"https://example.com/p/dijkstra%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%8F%8Apython%E5%AE%9E%E7%8E%B0/","title":"Dijkstra算法原理及Python实现"},{"content":"标题 标题2 ","date":"2025-04-13T14:44:25+08:00","image":"https://example.com/p/first_test/test_hu_22ab779589b0bb50.png","permalink":"https://example.com/p/first_test/","title":"First_test"},{"content":"正文测试 而这些并不是完全重要，更加重要的问题是， 带着这些问题，我们来审视一下学生会退会。 既然如何， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 我们不得不面对一个非常尴尬的事实，那就是， 可是，即使是这样，学生会退会的出现仍然代表了一定的意义。 学生会退会，发生了会如何，不发生又会如何。 经过上述讨论， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 学生会退会，到底应该如何实现。 这样看来， 在这种困难的抉择下，本人思来想去，寝食难安。 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 就我个人来说，学生会退会对我的意义，不能不说非常重大。 莎士比亚曾经提到过，人的一生是短的，但如果卑劣地过这一生，就太长了。这似乎解答了我的疑惑。 莫扎特说过一句富有哲理的话，谁和我一样用功，谁就会和我一样成功。这启发了我， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 学生会退会，到底应该如何实现。 一般来说， 从这个角度来看， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 在这种困难的抉择下，本人思来想去，寝食难安。 了解清楚学生会退会到底是一种怎么样的存在，是解决一切问题的关键。 一般来说， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 问题的关键究竟为何？ 而这些并不是完全重要，更加重要的问题是。\n奥斯特洛夫斯基曾经说过，共同的事业，共同的斗争，可以使人们产生忍受一切的力量。　带着这句话，我们还要更加慎重的审视这个问题： 一般来讲，我们都必须务必慎重的考虑考虑。 既然如此， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 带着这些问题，我们来审视一下学生会退会。 我认为， 我认为， 在这种困难的抉择下，本人思来想去，寝食难安。 问题的关键究竟为何？ 每个人都不得不面对这些问题。 在面对这种问题时， 要想清楚，学生会退会，到底是一种怎么样的存在。 我认为， 既然如此， 每个人都不得不面对这些问题。 在面对这种问题时， 那么， 我认为， 学生会退会因何而发生。\n引用 思念是最暖的忧伤像一双翅膀\n让我停不了飞不远在过往游荡\n不告而别的你 就算为了我着想\n这么沉痛的呵护 我怎么能翱翔\n最暖的憂傷 - 田馥甄\n图片 1 2 3 ![Photo by Florian Klauer on Unsplash](florian-klauer-nptLmg6jqDo-unsplash.jpg) ![Photo by Luca Bravo on Unsplash](luca-bravo-alS7ewQ41M8-unsplash.jpg) ![Photo by Helena Hertz on Unsplash](helena-hertz-wWZzXlDpMog-unsplash.jpg) ![Photo by Hudai Gayiran on Unsplash](hudai-gayiran-3Od_VKcDEAA-unsplash.jpg) 相册语法来自 Typlog\n","date":"2020-09-09T00:00:00Z","image":"https://example.com/p/test-chinese/helena-hertz-wWZzXlDpMog-unsplash_hu_2307260c751d0e0b.jpg","permalink":"https://example.com/p/test-chinese/","title":"Chinese Test"}]