[{"content":"åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ -4.5. æƒé‡è¡°å‡ ä»£ç  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 %matplotlib inline import torch from torch import nn from d2l import torch as d2l n_train, n_test, num_inputs, batch_size = 20, 100, 200, 5 true_w, true_b = torch.ones((num_inputs, 1)) * 0.01, 0.05 # d2l.synthetic_dataä¼šç”Ÿæˆç”Ÿæˆæ»¡è¶³ğ‘¦=ğ‘‹ğ‘¤+ğ‘+ğœ–çš„æ•°æ®ï¼Œè¿”å› (features, labels) ä¸¤ä¸ªå¼ é‡ train_data = d2l.synthetic_data(true_w, true_b, n_train) # d2l.load_array((features, labels), batch_size, is_train)ç”¨ TensorDataset + DataLoader æ‰“åŒ…æˆå°æ‰¹é‡æ•°æ®è¿­ä»£å™¨ã€‚ # å¾—åˆ°çš„train_iter æ¯æ¬¡è¿­ä»£ç»™ä¸€æ‰¹ (X, y)ï¼Œå½¢çŠ¶åˆ†åˆ«æ˜¯ (batch_size, 200) å’Œ (batch_size, 1) train_iter = d2l.load_array(train_data, batch_size) test_data = d2l.synthetic_data(true_w, true_b, n_test) test_iter = d2l.load_array(test_data, batch_size, is_train=False) 1 2 3 4 5 6 def init_params(): w = torch.normal(0, 1, size=(num_inputs, 1), requires_grad=True) b = torch.zeros(1, requires_grad=True) return [w, b] def l2_penalty(w): return torch.sum(w.pow(2)) / 2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def train(lambd): w, b = init_params() # æ­¤å¤„çš„lossæ˜¯ä¸å¸¦L2æƒ©ç½šé¡¹çš„æŸå¤±å‡½æ•° net, loss = lambda X: d2l.linreg(X, w, b), d2l.squared_loss num_epochs, lr = 100, 0.003 animator = d2l.Animator(xlabel=\u0026#39;epochs\u0026#39;, ylabel=\u0026#39;loss\u0026#39;, yscale=\u0026#39;log\u0026#39;, xlim=[5, num_epochs], legend=[\u0026#39;train\u0026#39;, \u0026#39;test\u0026#39;]) for epoch in range(num_epochs): for X, y in train_iter: # å¢åŠ äº†L2èŒƒæ•°æƒ©ç½šé¡¹ï¼Œ # å¹¿æ’­æœºåˆ¶ä½¿l2_penalty(w)æˆä¸ºä¸€ä¸ªé•¿åº¦ä¸ºbatch_sizeçš„å‘é‡ l = loss(net(X), y) + lambd * l2_penalty(w) l.sum().backward() d2l.sgd([w, b], lr, batch_size) if (epoch + 1) % 5 == 0: animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss), d2l.evaluate_loss(net, test_iter, loss))) print(\u0026#39;wçš„L2èŒƒæ•°æ˜¯ï¼š\u0026#39;, torch.norm(w).item()) 1 2 # ä¸ç”¨æ­£åˆ™åŒ– train(lambd=0) 1 2 # é€‚ä¸­æ­£åˆ™åŒ– train(lambd=3) 1 2 # å¼ºæ­£åˆ™åŒ– train(lambd=10) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # ä½¿ç”¨æ¡†æ¶è‡ªå¸¦çš„æ–¹æ³•å®ç°L2æ­£åˆ™åŒ– def train_concise(wd): net = nn.Sequential(nn.Linear(num_inputs, 1)) for param in net.parameters(): param.data.normal_() loss = nn.MSELoss(reduction=\u0026#39;none\u0026#39;) num_epochs, lr = 100, 0.003 # net[0].weight â†’ è®¾ç½® weight_decay=wdï¼Œè¡¨ç¤ºåœ¨æ›´æ–°æ—¶è‡ªåŠ¨åŠ ä¸Š L2 æ­£åˆ™é¡¹æ¢¯åº¦ # åç½®å‚æ•°æ²¡æœ‰è¡°å‡ trainer = torch.optim.SGD([ {\u0026#34;params\u0026#34;:net[0].weight,\u0026#39;weight_decay\u0026#39;: wd}, {\u0026#34;params\u0026#34;:net[0].bias}], lr=lr) animator = d2l.Animator(xlabel=\u0026#39;epochs\u0026#39;, ylabel=\u0026#39;loss\u0026#39;, yscale=\u0026#39;log\u0026#39;, xlim=[5, num_epochs], legend=[\u0026#39;train\u0026#39;, \u0026#39;test\u0026#39;]) for epoch in range(num_epochs): for X, y in train_iter: trainer.zero_grad() # æ¸…é™¤ä¸Šä¸€æ­¥çš„æ¢¯åº¦ # loss(...) è®¡ç®—é€æ ·æœ¬çš„ MSE æŸå¤±ï¼ˆä¸å«æ­£åˆ™é¡¹ï¼ŒL2 æ­£åˆ™åŒ–ç”±ä¼˜åŒ–å™¨åœ¨æ¢¯åº¦æ›´æ–°æ—¶è‡ªåŠ¨æ·»åŠ ï¼‰ l = loss(net(X), y) # net(X)å‰å‘è®¡ç®—é¢„æµ‹å€¼ # .mean()ï¼šè½¬æˆæ ‡é‡ï¼ˆæ‰¹å†…å¹³å‡ï¼‰ï¼Œè¿™æ · backward() æ‰èƒ½è¿è¡Œ # .backward()ï¼šåå‘ä¼ æ’­ï¼Œè®¡ç®—çº¯æ•°æ®è¯¯å·®çš„æ¢¯åº¦ï¼› # ä¹‹ååœ¨ trainer.step() é˜¶æ®µï¼Œä¼˜åŒ–å™¨ä¼šåœ¨æ¢¯åº¦ä¸­é¢å¤–åŠ ä¸Š wd * wï¼ˆå®ç° L2 æ­£åˆ™åŒ–çš„æ•ˆæœï¼‰ l.mean().backward() trainer.step() # æŒ‰ SGD è§„åˆ™æ›´æ–°å‚æ•° if (epoch + 1) % 5 == 0: animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss), d2l.evaluate_loss(net, test_iter, loss))) print(\u0026#39;wçš„L2èŒƒæ•°ï¼š\u0026#39;, net[0].weight.norm().item()) 1 train_concise(0) 1 train_concise(3) 1 train_concise(10) é—®é¢˜æ€»ç»“ é—®1ï¼šw.pow(2)å…·ä½“æ˜¯æ€ä¹ˆè®¡ç®—çš„ï¼Œwä¸æ˜¯ä¸€ä¸ªçŸ©é˜µå— w åœ¨è¿™é‡Œæ˜¯ä¸€ä¸ªå½¢çŠ¶ (200, 1) çš„äºŒç»´å¼ é‡ï¼ˆå¯ä»¥çœ‹ä½œ 200Ã—1 çŸ©é˜µï¼‰ï¼Œw.pow(2) æ˜¯ é€å…ƒç´ å¹³æ–¹ è¿ç®—ï¼Œä¸æ˜¯çŸ©é˜µä¹˜æ³•å¹³æ–¹ã€‚\nå³å¯¹ w ä¸­çš„æ¯ä¸€ä¸ªå…ƒç´  w_i_j å•ç‹¬å¹³æ–¹ï¼Œå¾—åˆ°çš„æ–°å¼ é‡çš„å½¢çŠ¶å’Œ w å®Œå…¨ä¸€æ ·ã€‚\né—®2ï¼štrain()å‡½æ•°ä¸­lambdè¿™ä¸ªå‚æ•°æœ‰ä»€ä¹ˆæ„ä¹‰ lambd å°±æ˜¯ L2 æ­£åˆ™åŒ–çš„ç³»æ•°ï¼ˆä¹Ÿå«æƒé‡è¡°å‡ç³»æ•°ã€regularization coefficientï¼‰ï¼Œå®ƒç›´æ¥æ§åˆ¶äº†æ­£åˆ™é¡¹åœ¨æ€»æŸå¤±ä¸­æ‰€å çš„æ¯”é‡ã€‚\ntrain()å‡½æ•°ä¸­å®šä¹‰çš„æŸå¤±å‡½æ•°å½¢å¼ä¸ºï¼š\n$$ Î» è¶Šå¤§ â†’ æ­£åˆ™åŒ–æƒ©ç½šé¡¹è¶Šé‡è¦ â†’ æ¨¡å‹ä¼šæ›´å¼ºçƒˆåœ°å‹ç¼©æƒé‡çš„å¤§å° â†’ æƒé‡çš„ L2 èŒƒæ•°âˆ¥ğ‘¤âˆ¥_2ä¼šå˜å°\\\\ Î» è¶Šå° â†’ æ­£åˆ™åŒ–çš„ä½œç”¨è¶Šå¼± â†’ æ›´æ¥è¿‘æ™®é€šçš„æœ€å°äºŒä¹˜å›å½’ã€‚ $$ é—®3ï¼š w çš„ L2 èŒƒæ•°åœ¨è¿™é‡Œåˆ°åº•æ„å‘³ç€ä»€ä¹ˆ w æ˜¯ä¸€ä¸ª (200Ã—1) çš„åˆ—å‘é‡ï¼Œä»£è¡¨ 200 ä¸ªè¾“å…¥ç‰¹å¾çš„æƒé‡ç³»æ•°ã€‚\nL2 èŒƒæ•°ï¼ˆEuclidean normï¼‰å°±æ˜¯æŠŠå®ƒçœ‹ä½œä¸€ä¸ªç‚¹ï¼Œæµ‹é‡å®ƒç¦»åŸç‚¹æœ‰å¤šè¿œï¼š $$ âˆ¥wâˆ¥_2 = \\sqrt{w_1^2 +w_2^2 +â‹¯+w_{200}^2} $$ è¿™å°±åƒæµ‹é‡ä¸€ä¸ª 200 ç»´ç©ºé—´é‡Œçš„å‘é‡çš„â€œé•¿åº¦â€ï¼ˆå®ƒæ˜¯æƒé‡å‘é‡çš„é•¿åº¦ï¼Œåœ¨æ•°å­¦ä¸Šå°±æ˜¯åˆ°åŸç‚¹çš„è·ç¦»ï¼‰ã€‚\nå€¼è¶Šå¤§ â†’ æƒé‡æ•´ä½“å¹…åº¦è¶Šå¤§ï¼Œè¯´æ˜æ¨¡å‹æ›´â€œæ¿€è¿›â€ï¼Œå¯¹è¾“å…¥å˜åŒ–ååº”å¯èƒ½æ›´æ•æ„Ÿï¼Œè¿‡æ‹Ÿåˆé£é™©æ›´é«˜ã€‚\nå€¼è¶Šå° â†’ æƒé‡æ•´ä½“å¹…åº¦è¶Šå°ï¼Œæ¨¡å‹æ›´å¹³æ»‘ï¼Œå¯¹æ–°æ•°æ®å¯èƒ½æ³›åŒ–æ›´å¥½ï¼ˆä½†ä¹Ÿå¯èƒ½æ¬ æ‹Ÿåˆï¼‰ã€‚\n","date":"2025-08-11T11:44:25+08:00","image":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-4.5.-%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F/index_hu_ee6b10762b6f6f6e.png","permalink":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-4.5.-%E6%9D%83%E9%87%8D%E8%A1%B0%E5%87%8F/","title":"åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ -4.5. æƒé‡è¡°å‡"},{"content":"åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ -4.3. å¤šå±‚æ„ŸçŸ¥æœºçš„ç®€æ´å®ç° ä»£ç  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 import torch from torch import nn from d2l import torch as d2l net = nn.Sequential(nn.Flatten(), nn.Linear(784, 256), nn.ReLU(), nn.Linear(256, 10)) # éå†ç¥ç»ç½‘ç»œçš„å„å±‚çš„å‡½æ•°ï¼Œè‹¥ä¸ºçº¿æ€§å±‚ï¼Œåˆ™æŒ‰ç…§å‡å€¼ä¸º0ã€æ ‡å‡†å·®ä¸º0.01çš„æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–æƒé‡ def init_weights(m): if type(m) == nn.Linear: nn.init.normal_(m.weight, std=0.01) # apply(fn) ä¼šæŠŠä¼ å…¥çš„å‡½æ•° fn åº”ç”¨åˆ°å½“å‰ Module ä»¥åŠå®ƒçš„æ‰€æœ‰å­æ¨¡å—ï¼ˆsubmodulesï¼‰ä¸Šï¼Œé€’å½’è°ƒç”¨ net.apply(init_weights); batch_size, lr, num_epochs = 256, 0.1, 10 loss = nn.CrossEntropyLoss(reduction=\u0026#39;none\u0026#39;) trainer = torch.optim.SGD(net.parameters(), lr=lr) train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) # ç´¯åŠ å™¨ class Accumulator: \u0026#34;\u0026#34;\u0026#34;åœ¨nä¸ªå˜é‡ä¸Šç´¯åŠ \u0026#34;\u0026#34;\u0026#34; def __init__(self, n): self.data = [0.0] * n def add(self, *args): self.data = [a + float(b) for a, b in zip(self.data, args)] def reset(self): self.data = [0.0] * len(self.data) def __getitem__(self, idx): return self.data[idx] # å‡†ç¡®ç‡ def accuracy(y_hat, y): # y_hat æ˜¯ logits æˆ– æ¦‚ç‡éƒ½å¯ä»¥ï¼›äºŒç»´æ—¶æŒ‰ç±»åˆ«ç»´å– argmax if y_hat.ndim \u0026gt; 1 and y_hat.shape[1] \u0026gt; 1: y_hat = y_hat.argmax(dim=1) return (y_hat.type(y.dtype) == y).float().mean().item() # åœ¨æ•°æ®é›†ä¸Šè¯„ä¼°å‡†ç¡®ç‡ def evaluate_accuracy(net, data_iter): if isinstance(net, torch.nn.Module): net.eval() metric = Accumulator(2) # [é¢„æµ‹æ­£ç¡®æ•°, æ€»æ ·æœ¬æ•°] with torch.no_grad(): for X, y in data_iter: metric.add((net(X).argmax(dim=1) == y).sum(), y.numel()) return metric[0] / metric[1] # è®­ç»ƒä¸€è½® def train_epoch_ch3(net, train_iter, loss, updater): if isinstance(net, torch.nn.Module): net.train() metric = Accumulator(3) # [æŸå¤±å’Œ, é¢„æµ‹æ­£ç¡®æ•°, æ ·æœ¬æ€»æ•°] for X, y in train_iter: y_hat = net(X) l = loss(y_hat, y) # è¿™é‡Œå…¼å®¹ CrossEntropyLoss(reduction=\u0026#39;none\u0026#39;) if isinstance(updater, torch.optim.Optimizer): updater.zero_grad() l.mean().backward() updater.step() else: l.sum().backward() updater(X.shape[0]) metric.add(l.sum(), (y_hat.argmax(dim=1) == y).sum(), y.numel()) return metric[0] / metric[2], metric[1] / metric[2] # è®­ç»ƒä¸»æµç¨‹ï¼ˆå«ç®€å•æ‰“å°ï¼‰ def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater): for epoch in range(num_epochs): train_loss, train_acc = train_epoch_ch3(net, train_iter, loss, updater) test_acc = evaluate_accuracy(net, test_iter) print(f\u0026#39;epoch {epoch+1}: \u0026#39; f\u0026#39;loss {train_loss:.4f}, train acc {train_acc:.3f}, test acc {test_acc:.3f}\u0026#39;) train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) è¿è¡Œç»“æœ ","date":"2025-08-10T10:44:25+08:00","image":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-4.3.-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/index_hu_8280d38d476c6339.png","permalink":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-4.3.-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/","title":"åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ -4.3. å¤šå±‚æ„ŸçŸ¥æœºçš„ç®€æ´å®ç°"},{"content":"åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ -4.2. å¤šå±‚æ„ŸçŸ¥æœºçš„ä»é›¶å¼€å§‹å®ç° ä»£ç  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 import torch from torch import nn from d2l import torch as d2l batch_size = 256 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) num_inputs, num_outputs, num_hiddens = 784, 10, 256 W1 = nn.Parameter(torch.randn( num_inputs, num_hiddens, requires_grad=True) * 0.01) b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True)) W2 = nn.Parameter(torch.randn( num_hiddens, num_outputs, requires_grad=True) * 0.01) b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True)) params = [W1, b1, W2, b2] def relu(X): # åˆ›å»ºä¸€ä¸ªå½¢çŠ¶ï¼Œdtypeï¼Œdeviceä¸Xå®Œå…¨ç›¸åŒçš„å…¨0å¼ é‡ # dtype å†³å®šäº†å¼ é‡é‡Œå•ä¸ªå…ƒç´ çš„æ•°å€¼ç±»å‹å’Œç²¾åº¦ # device è¡¨ç¤ºå¼ é‡å­˜å‚¨å’Œè®¡ç®—æ‰€åœ¨çš„ç¡¬ä»¶è®¾å¤‡ a = torch.zeros_like(X) return torch.max(X, a) def net(X): X = X.reshape((-1, num_inputs)) # @ä»£è¡¨çŸ©é˜µä¹˜æ³• H = relu(X@W1 + b1) return (H@W2 + b2) # é»˜è®¤å¯¹æœ€åä¸€å±‚è¿›è¡Œsoftmaxå¤„ç† loss = nn.CrossEntropyLoss(reduction=\u0026#39;none\u0026#39;) num_epochs, lr = 10, 0.1 updater = torch.optim.SGD(params, lr=lr) # ç´¯åŠ å™¨ class Accumulator: \u0026#34;\u0026#34;\u0026#34;åœ¨nä¸ªå˜é‡ä¸Šç´¯åŠ \u0026#34;\u0026#34;\u0026#34; def __init__(self, n): self.data = [0.0] * n def add(self, *args): self.data = [a + float(b) for a, b in zip(self.data, args)] def reset(self): self.data = [0.0] * len(self.data) def __getitem__(self, idx): return self.data[idx] # å‡†ç¡®ç‡ def accuracy(y_hat, y): # y_hat æ˜¯ logits æˆ– æ¦‚ç‡éƒ½å¯ä»¥ï¼›äºŒç»´æ—¶æŒ‰ç±»åˆ«ç»´å– argmax if y_hat.ndim \u0026gt; 1 and y_hat.shape[1] \u0026gt; 1: y_hat = y_hat.argmax(dim=1) return (y_hat.type(y.dtype) == y).float().mean().item() # åœ¨æ•°æ®é›†ä¸Šè¯„ä¼°å‡†ç¡®ç‡ def evaluate_accuracy(net, data_iter): if isinstance(net, torch.nn.Module): net.eval() metric = Accumulator(2) # [é¢„æµ‹æ­£ç¡®æ•°, æ€»æ ·æœ¬æ•°] with torch.no_grad(): for X, y in data_iter: metric.add((net(X).argmax(dim=1) == y).sum(), y.numel()) return metric[0] / metric[1] # è®­ç»ƒä¸€è½® def train_epoch_ch3(net, train_iter, loss, updater): if isinstance(net, torch.nn.Module): net.train() metric = Accumulator(3) # [æŸå¤±å’Œ, é¢„æµ‹æ­£ç¡®æ•°, æ ·æœ¬æ€»æ•°] for X, y in train_iter: y_hat = net(X) l = loss(y_hat, y) # è¿™é‡Œå…¼å®¹ CrossEntropyLoss(reduction=\u0026#39;none\u0026#39;) if isinstance(updater, torch.optim.Optimizer): updater.zero_grad() l.mean().backward() updater.step() else: l.sum().backward() updater(X.shape[0]) metric.add(l.sum(), (y_hat.argmax(dim=1) == y).sum(), y.numel()) return metric[0] / metric[2], metric[1] / metric[2] # è®­ç»ƒä¸»æµç¨‹ï¼ˆå«ç®€å•æ‰“å°ï¼‰ def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater): for epoch in range(num_epochs): train_loss, train_acc = train_epoch_ch3(net, train_iter, loss, updater) test_acc = evaluate_accuracy(net, test_iter) print(f\u0026#39;epoch {epoch+1}: \u0026#39; f\u0026#39;loss {train_loss:.4f}, train acc {train_acc:.3f}, test acc {test_acc:.3f}\u0026#39;) train_ch3(net, train_iter, test_iter, loss, num_epochs, updater) def predict_ch3(net, test_iter, n=6): #@save \u0026#34;\u0026#34;\u0026#34;éšæœºé€‰nå¼ å›¾ç‰‡ï¼Œå±•ç¤ºçœŸå®å’Œé¢„æµ‹æ ‡ç­¾\u0026#34;\u0026#34;\u0026#34; for X, y in test_iter: break # å–ç¬¬ä¸€ä¸ªbatch trues = d2l.get_fashion_mnist_labels(y) # çœŸå®æ ‡ç­¾ï¼ˆè½¬æ–‡æœ¬ï¼‰ preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1)) # é¢„æµ‹æ ‡ç­¾ï¼ˆè½¬æ–‡æœ¬ï¼‰ # åˆå¹¶â€œçœŸå®+é¢„æµ‹â€ä½œä¸ºæ ‡é¢˜ titles = [true +\u0026#39;\\n\u0026#39; + pred for true, pred in zip(trues, preds)] # å¯è§†åŒ–å‰nå¼ å›¾ç‰‡åŠæ ‡ç­¾ d2l.show_images( X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n]) predict_ch3(net, test_iter) è¿è¡Œç»“æœ ","date":"2025-08-09T10:44:25+08:00","image":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-4.2.-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0/index_hu_6952dd3e586c4f57.png","permalink":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-4.2.-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0/","title":"åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ -4.2. å¤šå±‚æ„ŸçŸ¥æœºçš„ä»é›¶å¼€å§‹å®ç°"},{"content":"åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ -3.7. softmaxå›å½’çš„ç®€æ´å®ç° ä»£ç  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 import torch from torch import nn from d2l import torch as d2l batch_size = 256 train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size) # æƒ³è¦æŸ¥çœ‹train_iterçš„å½¢çŠ¶ä¸èƒ½train_iter.shape # å› ä¸ºtrain_iter æ˜¯ PyTorch çš„ DataLoader å¯¹è±¡ï¼Œæœ¬è´¨ä¸Šæ˜¯ä¸ªå¯è¿­ä»£å™¨ï¼ˆiteratorï¼‰ï¼Œå¹¶ä¸æ˜¯ä¸€ä¸ªå¼ é‡ï¼ˆtorch.Tensorï¼‰ï¼Œæ‰€ä»¥å®ƒæ²¡æœ‰ .shape å±æ€§ # iter():æŠŠä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡ï¼ˆæ¯”å¦‚ train_iterã€listã€tupleï¼‰å˜æˆä¸€ä¸ªè¿­ä»£å™¨å¯¹è±¡ï¼Œè¿­ä»£å™¨å¯¹è±¡æ˜¯å¯ä»¥ç”¨ next() ä¸€æ¬¡ä¸€æ¬¡å–æ•°æ®çš„ # next():ä»è¿­ä»£å™¨å¯¹è±¡é‡Œå–ä¸‹ä¸€ä¸ªå…ƒç´ ï¼Œæ¯è°ƒç”¨ä¸€æ¬¡ next()ï¼Œè¿­ä»£å™¨å°±å¾€å‰èµ°ä¸€æ­¥ï¼Œç›´åˆ°å–å®Œæ‰€æœ‰å…ƒç´ ï¼Œå¦‚æœå†è°ƒç”¨ next()ï¼Œä¼šæŠ¥ StopIteration é”™è¯¯ # æ¯æ¬¡å–ä¸€ä¸ªbatch X, y = next(iter(train_iter)) print(X.shape) # å›¾ç‰‡æ‰¹æ¬¡çš„å½¢çŠ¶ print(y.shape) # æ ‡ç­¾æ‰¹æ¬¡çš„å½¢çŠ¶ # PyTorchä¸ä¼šéšå¼åœ°è°ƒæ•´è¾“å…¥çš„å½¢çŠ¶ã€‚å› æ­¤ï¼Œ # nn.Linear å…¨è¿æ¥å±‚è¦æ±‚è¾“å…¥æ˜¯äºŒç»´æ‰€ä»¥è¦åœ¨ä¹‹å‰åŠ å…¥å±•å¹³å±‚ï¼Œå°†(batchsize, 1, 28, 28)çš„è¾“å…¥å½¢çŠ¶è½¬æ¢ä¸º(batchsize,784) net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10)) def init_weights(m): if type(m) == nn.Linear: nn.init.normal_(m.weight, std=0.01) net.apply(init_weights); loss = nn.CrossEntropyLoss(reduction=\u0026#39;none\u0026#39;) trainer = torch.optim.SGD(net.parameters(), lr=0.1) num_epochs = 10 # d2låŒ…é‡Œæ²¡æœ‰train_ch3æ–¹æ³• # d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) # ç´¯åŠ å™¨ class Accumulator: \u0026#34;\u0026#34;\u0026#34;åœ¨nä¸ªå˜é‡ä¸Šç´¯åŠ \u0026#34;\u0026#34;\u0026#34; def __init__(self, n): self.data = [0.0] * n def add(self, *args): self.data = [a + float(b) for a, b in zip(self.data, args)] def reset(self): self.data = [0.0] * len(self.data) def __getitem__(self, idx): return self.data[idx] # å‡†ç¡®ç‡ def accuracy(y_hat, y): # y_hat æ˜¯ logits æˆ– æ¦‚ç‡éƒ½å¯ä»¥ï¼›äºŒç»´æ—¶æŒ‰ç±»åˆ«ç»´å– argmax if y_hat.ndim \u0026gt; 1 and y_hat.shape[1] \u0026gt; 1: y_hat = y_hat.argmax(dim=1) return (y_hat.type(y.dtype) == y).float().mean().item() # åœ¨æ•°æ®é›†ä¸Šè¯„ä¼°å‡†ç¡®ç‡ def evaluate_accuracy(net, data_iter): if isinstance(net, torch.nn.Module): net.eval() metric = Accumulator(2) # [é¢„æµ‹æ­£ç¡®æ•°, æ€»æ ·æœ¬æ•°] with torch.no_grad(): for X, y in data_iter: metric.add((net(X).argmax(dim=1) == y).sum(), y.numel()) return metric[0] / metric[1] # è®­ç»ƒä¸€è½® def train_epoch_ch3(net, train_iter, loss, updater): if isinstance(net, torch.nn.Module): net.train() metric = Accumulator(3) # [æŸå¤±å’Œ, é¢„æµ‹æ­£ç¡®æ•°, æ ·æœ¬æ€»æ•°] for X, y in train_iter: y_hat = net(X) l = loss(y_hat, y) # è¿™é‡Œå…¼å®¹ CrossEntropyLoss(reduction=\u0026#39;none\u0026#39;) if isinstance(updater, torch.optim.Optimizer): updater.zero_grad() l.mean().backward() updater.step() else: l.sum().backward() updater(X.shape[0]) metric.add(l.sum(), (y_hat.argmax(dim=1) == y).sum(), y.numel()) return metric[0] / metric[2], metric[1] / metric[2] # è®­ç»ƒä¸»æµç¨‹ï¼ˆå«ç®€å•æ‰“å°ï¼‰ def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater): for epoch in range(num_epochs): train_loss, train_acc = train_epoch_ch3(net, train_iter, loss, updater) test_acc = evaluate_accuracy(net, test_iter) print(f\u0026#39;epoch {epoch+1}: \u0026#39; f\u0026#39;loss {train_loss:.4f}, train acc {train_acc:.3f}, test acc {test_acc:.3f}\u0026#39;) train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer) è¿è¡Œç»“æœ ","date":"2025-08-08T10:44:25+08:00","image":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-3.7.-softmax%E5%9B%9E%E5%BD%92%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/index_hu_4ec5be606bec4201.jpg","permalink":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-3.7.-softmax%E5%9B%9E%E5%BD%92%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/","title":"åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ -3.7. softmaxå›å½’çš„ç®€æ´å®ç°"},{"content":"åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ -3.6. softmaxå›å½’çš„ä»é›¶å¼€å§‹å®ç° ä»£ç  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 import torch from IPython import display from d2l import torch as d2l # å›¾åƒé¢„å¤„ç†æµæ°´çº¿ï¼ˆload_data_fashion_mnistç”¨åˆ°ï¼‰ from torchvision import transforms # æ•°æ®é›†åŠ è½½ï¼ˆload_data_fashion_mnistç”¨åˆ°FashionMNISTï¼‰ import torchvision # DataLoaderç­‰æ•°æ®æ‰¹å¤„ç†å·¥å…·ï¼ˆload_data_fashion_mnistç­‰ç”¨åˆ°ï¼‰ from torch.utils import data # é€‰æ‹©æ•°æ®åŠ è½½çº¿ç¨‹æ•° def get_dataloader_workers(): \u0026#34;\u0026#34;\u0026#34;ä½¿ç”¨å¤šå°‘ä¸ªè¿›ç¨‹æ¥è¯»å–æ•°æ®ã€‚winå»ºè®®1ï¼Œlinuxå»ºè®®4\u0026#34;\u0026#34;\u0026#34; return 4 # æ•°æ®åŠ è½½ä¸é¢„å¤„ç† def load_data_fashion_mnist(batch_size, resize=None): #@save # 1. åˆ›å»ºå¤„ç†æ“ä½œåˆ—è¡¨ï¼ˆå…ˆè½¬å¼ é‡ï¼Œå¿…è¦æ—¶resizeæ’åœ¨å‰é¢ï¼‰ # transæ˜¯ä¸€ä¸ªé•¿åº¦ä¸º1çš„åˆ—è¡¨ï¼Œåªæœ‰ToTensor()æ“ä½œçš„è¿™ä¸€ä¸ªå…ƒç´  trans = [transforms.ToTensor()] # å¦‚æœæœ‰resizeæ“ä½œï¼Œå°†å…¶æ’å…¥transåˆ—è¡¨ä¸­çš„é¦–ä½ if resize: trans.insert(0, transforms.Resize(resize)) # 2. ç»„è£…æˆå¤åˆå˜æ¢å™¨ trans = transforms.Compose(trans) # 3. åŠ è½½è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼ˆå›¾ç‰‡å°†è‡ªåŠ¨åšä¸Šè¿°é¢„å¤„ç†ï¼‰ mnist_train = torchvision.datasets.FashionMNIST( root=\u0026#34;../data\u0026#34;, train=True, transform=trans, download=True) mnist_test = torchvision.datasets.FashionMNIST( root=\u0026#34;../data\u0026#34;, train=False, transform=trans, download=True) # 4. ç”¨DataLoaderåˆ†æ‰¹åŠ è½½ï¼ˆè®­ç»ƒé›†æ‰“ä¹±ï¼Œæµ‹è¯•é›†ä¸æ‰“ä¹±ï¼‰ return (data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=get_dataloader_workers()), data.DataLoader(mnist_test, batch_size, shuffle=False, num_workers=get_dataloader_workers())) # è·å–è®­ç»ƒã€æµ‹è¯•é›†æ•°æ®æ‰¹é‡è¿­ä»£å™¨ batch_size = 256 train_iter, test_iter = load_data_fashion_mnist(batch_size) # å‚æ•°åˆå§‹åŒ– # 28*28åƒç´ =784ï¼Œè¾“å…¥ç‰¹å¾é•¿åº¦ num_inputs = 784 # 10ç±»ï¼ˆæ¯ä¸ªå›¾ç‰‡å±äº0~9ä¹‹ä¸€ï¼‰ num_outputs = 10 # æƒé‡å‚æ•°ï¼ˆæ­£æ€åˆ†å¸ƒåˆå§‹åŒ–ï¼‰ï¼Œå½¢çŠ¶[784,10] W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True) b = torch.zeros(num_outputs, requires_grad=True) # åç½®å‚æ•° # Softmaxå‡½æ•° def softmax(X): X_exp = torch.exp(X) # å¯¹æ¯ä¸ªå…ƒç´ åšæŒ‡æ•°è¿ç®— partition = X_exp.sum(1, keepdim=True) # æ¯è¡Œæ±‚å’Œå¾—åˆ°åˆ†æ¯ï¼ˆåˆ—å‘é‡ï¼‰ï¼Œä¿ç•™äºŒç»´ç»“æ„ return X_exp / partition # ç”¨å¹¿æ’­æœºåˆ¶ï¼Œæ¯ä¸ªå…ƒç´ é™¤ä»¥å¯¹åº”åˆ†æ¯ï¼Œå¾—åˆ°æ¦‚ç‡ # çº¿æ€§åˆ†ç±»å™¨ï¼ˆå‰å‘ä¼ æ’­ï¼‰ def net(X): # 1. Xå±•å¹³æˆäºŒç»´(batch,784)ï¼›2. ä¹˜ä»¥æƒé‡å†åŠ åç½®ï¼›3. é€å…¥softmaxå¾—åˆ°æ¦‚ç‡ return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b) # äº¤å‰ç†µæŸå¤±å‡½æ•° def cross_entropy(y_hat, y): # å–æ¯ä¸ªæ ·æœ¬çœŸå®ç±»åˆ«çš„æ¦‚ç‡ï¼Œå–å¯¹æ•°åå–è´Ÿï¼Œå¾—åˆ°æŸå¤± return - torch.log(y_hat[range(len(y_hat)), y]) # è®¡ç®—å‡†ç¡®ç‡çš„å‡½æ•° def accuracy(y_hat, y): #@save \u0026#34;\u0026#34;\u0026#34;è®¡ç®—é¢„æµ‹æ­£ç¡®çš„æ•°é‡\u0026#34;\u0026#34;\u0026#34; # å¦‚æœy_hatæ˜¯æ¦‚ç‡åˆ†å¸ƒï¼Œå…ˆè½¬æˆé¢„æµ‹ç±»åˆ«ï¼ˆå–æœ€å¤§æ¦‚ç‡çš„ä¸‹æ ‡ï¼‰ if len(y_hat.shape) \u0026gt; 1 and y_hat.shape[1] \u0026gt; 1: y_hat = y_hat.argmax(axis=1) # æ¯”è¾ƒé¢„æµ‹ç±»åˆ«å’ŒçœŸå®æ ‡ç­¾ï¼Œå¾—åˆ°å¸ƒå°”å‹ï¼ˆTrue/Falseï¼‰ cmp = y_hat.type(y.dtype) == y return float(cmp.type(y.dtype).sum()) # ç»Ÿè®¡é¢„æµ‹æ­£ç¡®ä¸ªæ•° # åœ¨å®Œæ•´æ•°æ®é›†ä¸Šè¯„ä¼°å‡†ç¡®ç‡ def evaluate_accuracy(net, data_iter): \u0026#34;\u0026#34;\u0026#34;è®¡ç®—åœ¨æŒ‡å®šæ•°æ®é›†ä¸Šæ¨¡å‹çš„ç²¾åº¦\u0026#34;\u0026#34;\u0026#34; if isinstance(net, torch.nn.Module): net.eval() # å¦‚æœæ˜¯æ ‡å‡†PyTorchæ¨¡å‹ï¼Œåˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼ metric = Accumulator(2) # [é¢„æµ‹å¯¹æ•°ï¼Œæ€»æ ·æœ¬æ•°] with torch.no_grad(): # ç¦ç”¨æ¢¯åº¦ï¼ŒèŠ‚çœå†…å­˜å’Œè®¡ç®— for X, y in data_iter: metric.add(accuracy(net(X), y), y.numel()) return metric[0] / metric[1] # è¿”å›å‡†ç¡®ç‡ # å¤šå˜é‡ç´¯åŠ å™¨å·¥å…·ç±» class Accumulator: #@save \u0026#34;\u0026#34;\u0026#34;åœ¨nä¸ªå˜é‡ä¸Šç´¯åŠ \u0026#34;\u0026#34;\u0026#34; def __init__(self, n): self.data = [0.0] * n # åˆå§‹åŒ–é•¿åº¦ä¸ºnçš„åˆ—è¡¨ def add(self, *args): self.data = [a + float(b) for a, b in zip(self.data, args)] # ä½ç½®å¯¹é½ç›¸åŠ  def reset(self): self.data = [0.0] * len(self.data) # __getitem__æ˜¯pythonå†…ç½®çš„é­”æ³•æ–¹æ³• def __getitem__(self, idx): return self.data[idx] # æ”¯æŒç´¢å¼•è¯»å–ï¼ˆobj[idx]ï¼‰ # ç¤ºä¾‹ï¼šè¯„ä¼°å½“å‰ç½‘ç»œåœ¨æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡ evaluate_accuracy(net, test_iter) # è®­ç»ƒä¸€è½®epoch def train_epoch_ch3(net, train_iter, loss, updater): #@save \u0026#34;\u0026#34;\u0026#34;è®­ç»ƒæ¨¡å‹ä¸€ä¸ªè¿­ä»£å‘¨æœŸ\u0026#34;\u0026#34;\u0026#34; if isinstance(net, torch.nn.Module): net.train() # å¦‚æœæ˜¯æ ‡å‡†æ¨¡å‹ï¼Œåˆ‡æ¢åˆ°è®­ç»ƒæ¨¡å¼ metric = Accumulator(3) # [æŸå¤±å’Œï¼Œé¢„æµ‹å¯¹æ•°ï¼Œæ ·æœ¬æ€»æ•°] for X, y in train_iter: # å‰å‘ä¼ æ’­ï¼Œè®¡ç®—é¢„æµ‹å’ŒæŸå¤± y_hat = net(X) l = loss(y_hat, y) # åå‘ä¼ æ’­ä¸å‚æ•°æ›´æ–°ï¼ˆä¸¤ç§æƒ…å†µï¼‰ if isinstance(updater, torch.optim.Optimizer): updater.zero_grad() l.mean().backward() updater.step() else: l.sum().backward() updater(X.shape[0]) # ç´¯åŠ ç»Ÿè®¡é‡ metric.add(float(l.sum()), accuracy(y_hat, y), y.numel()) # è¿”å›å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡ return metric[0] / metric[2], metric[1] / metric[2] # è®­ç»ƒè¿‡ç¨‹åŠ¨ç”»å¯è§†åŒ–ç±» class Animator: #@save \u0026#34;\u0026#34;\u0026#34;åœ¨åŠ¨ç”»ä¸­ç»˜åˆ¶æ•°æ®ï¼ˆæ”¯æŒå¤šæ›²çº¿ï¼‰\u0026#34;\u0026#34;\u0026#34; def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None, ylim=None, xscale=\u0026#39;linear\u0026#39;, yscale=\u0026#39;linear\u0026#39;, fmts=(\u0026#39;-\u0026#39;, \u0026#39;m--\u0026#39;, \u0026#39;g-.\u0026#39;, \u0026#39;r:\u0026#39;), nrows=1, ncols=1, figsize=(3.5, 2.5)): if legend is None: legend = [] d2l.use_svg_display() self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize) if nrows * ncols == 1: self.axes = [self.axes, ] # ä¼ é€’é…ç½®å‚æ•°ï¼Œä¾¿äºåç»­é‡ç»˜ self.config_axes = lambda: d2l.set_axes( self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend) self.X, self.Y, self.fmts = None, None, fmts def add(self, x, y): # å¢é‡å¼æ·»åŠ å¤šä¸ªæ•°æ®ç‚¹åˆ°æ›²çº¿ if not hasattr(y, \u0026#34;__len__\u0026#34;): y = [y] n = len(y) if not hasattr(x, \u0026#34;__len__\u0026#34;): x = [x] * n if not self.X: self.X = [[] for _ in range(n)] if not self.Y: self.Y = [[] for _ in range(n)] for i, (a, b) in enumerate(zip(x, y)): if a is not None and b is not None: self.X[i].append(a) self.Y[i].append(b) self.axes[0].cla() # æ¸…é™¤æ—§å†…å®¹ for x, y, fmt in zip(self.X, self.Y, self.fmts): self.axes[0].plot(x, y, fmt) self.config_axes() display.display(self.fig) display.clear_output(wait=True) # æ€»æ§è®­ç»ƒä¸»æµç¨‹å‡½æ•° def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater): #@save \u0026#34;\u0026#34;\u0026#34;è®­ç»ƒä¸»æ§æµç¨‹ï¼šæ¯epochè®­ç»ƒ/è¯„ä¼°/å¯è§†åŒ–\u0026#34;\u0026#34;\u0026#34; animator = Animator(xlabel=\u0026#39;epoch\u0026#39;, xlim=[1, num_epochs], ylim=[0.3, 0.9], legend=[\u0026#39;train loss\u0026#39;, \u0026#39;train acc\u0026#39;, \u0026#39;test acc\u0026#39;]) for epoch in range(num_epochs): train_metrics = train_epoch_ch3(net, train_iter, loss, updater) # è®­ç»ƒä¸€è½® test_acc = evaluate_accuracy(net, test_iter) # æµ‹è¯•é›†è¯„ä¼° animator.add(epoch + 1, train_metrics + (test_acc,)) # ç”»æ›²çº¿ train_loss, train_acc = train_metrics # è‡ªåŠ¨æ£€æµ‹æ¨¡å‹æ•ˆæœ assert train_loss \u0026lt; 0.5, train_loss assert train_acc \u0026lt;= 1 and train_acc \u0026gt; 0.7, train_acc assert test_acc \u0026lt;= 1 and test_acc \u0026gt; 0.7, test_acc # å­¦ä¹ ç‡ lr = 0.1 def updater(batch_size): # ç”¨d2lçš„SGDä¼˜åŒ–å™¨ return d2l.sgd([W, b], lr, batch_size) num_epochs = 10 # å¼€å§‹è®­ç»ƒå¹¶åŠ¨æ€å¯è§†åŒ– train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater) # å¯è§†åŒ–é¢„æµ‹æ•ˆæœçš„å‡½æ•° def predict_ch3(net, test_iter, n=6): #@save \u0026#34;\u0026#34;\u0026#34;éšæœºé€‰nå¼ å›¾ç‰‡ï¼Œå±•ç¤ºçœŸå®å’Œé¢„æµ‹æ ‡ç­¾\u0026#34;\u0026#34;\u0026#34; for X, y in test_iter: break # å–ç¬¬ä¸€ä¸ªbatch trues = d2l.get_fashion_mnist_labels(y) # çœŸå®æ ‡ç­¾ï¼ˆè½¬æ–‡æœ¬ï¼‰ preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1)) # é¢„æµ‹æ ‡ç­¾ï¼ˆè½¬æ–‡æœ¬ï¼‰ # åˆå¹¶â€œçœŸå®+é¢„æµ‹â€ä½œä¸ºæ ‡é¢˜ titles = [true +\u0026#39;\\n\u0026#39; + pred for true, pred in zip(trues, preds)] # å¯è§†åŒ–å‰nå¼ å›¾ç‰‡åŠæ ‡ç­¾ d2l.show_images( X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n]) # è¿è¡Œé¢„æµ‹å’Œå¯è§†åŒ– predict_ch3(net, test_iter) è¿è¡Œç»“æœ ","date":"2025-08-07T14:44:25+08:00","image":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-3.6.-softmax%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0/index_hu_b78a2939fab46f81.jpg","permalink":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-3.6.-softmax%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0/","title":"åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ -3.6. softmaxå›å½’çš„ä»é›¶å¼€å§‹å®ç°"},{"content":"åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ -3.3. çº¿æ€§å›å½’çš„ç®€æ´å®ç° ä»£ç  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 import numpy as np import torch from torch.utils import data from d2l import torch as d2l true_w = torch.tensor([2, -3.4]) true_b = 4.2 # ä½¿ç”¨d2låŒ…è‡ªå¸¦çš„åŠŸèƒ½ç”Ÿæˆç¬¦åˆy=wx+bçš„å¸¦å™ªå£°çš„æ•°æ®Xå’Œy features, labels = d2l.synthetic_data(true_w, true_b, 1000) def load_array(data_arrays, batch_size, is_train=True): #@save \u0026#34;\u0026#34;\u0026#34;æ„é€ ä¸€ä¸ªPyTorchæ•°æ®è¿­ä»£å™¨\u0026#34;\u0026#34;\u0026#34; # TensorDataset æ˜¯ä¸€ä¸ªæ•°æ®é›†ç±»å‹ï¼Œå°†å¤šä¸ªå¼ é‡ï¼ˆtensorï¼‰æ‰“åŒ…æˆä¸€ä¸ªå¯ç´¢å¼•çš„æ•°æ®é›† # *data_arrays çš„ * æ˜¯ Python çš„â€œæ‹†åŒ…â€è¯­æ³• # å¦‚æœ data_arrays æ˜¯ (features, labels)ï¼Œé‚£ä¹ˆ *data_arrays å°±ä¼šå±•å¼€æˆä¸¤ä¸ªå‚æ•°ï¼šTensorDataset(features, labels) dataset = data.TensorDataset(*data_arrays) # DataLoaderè¿”å›å¯è¿­ä»£å¯¹è±¡ # è¿”å›çš„ DataLoader æ”¯æŒå°æ‰¹é‡ã€è‡ªåŠ¨ä¹±åºï¼ˆè‹¥ is_train=Trueï¼‰ä»¥åŠé«˜æ•ˆè¿­ä»£ return data.DataLoader(dataset, batch_size, shuffle=is_train) batch_size = 10 data_iter = load_array((features, labels), batch_size) # æ‰“å°çš„æ˜¯ä¸€ä¸ªbatchçš„ç‰¹å¾å’Œæ ‡ç­¾ï¼Œä¸æ˜¯ä¸€å¯¹ï¼ˆæ˜¯ä¸€ç»„ï¼‰ print(\u0026#34;å–å‡ºä¸€ä¸ªbatchç»„å¤§å°çš„(X,y)æ•°æ®å¯¹ï¼š\u0026#34;,next(iter(data_iter))) # nnæ˜¯ç¥ç»ç½‘ç»œçš„ç¼©å†™ from torch import nn # nn æ˜¯ PyTorch çš„ç¥ç»ç½‘ç»œæ¨¡å— # nn.Linear(2, 1)è¡¨ç¤ºå…¨è¿æ¥å±‚ï¼Œè¾“å…¥ä¸º2ç»´ï¼Œè¾“å‡ºä¸º1ç»´ net = nn.Sequential(nn.Linear(2, 1)) # net[0]ï¼šç›¸å½“äºå– nn.Sequential é‡Œçš„ç¬¬ä¸€ä¸ªå±‚ï¼ˆè¿™é‡Œå°±æ˜¯ nn.Linear(2, 1)ï¼‰ # .weight è¡¨ç¤ºç¬¬ä¸€å±‚çš„æƒé‡å¼ é‡ï¼Œ.data ç›´æ¥è®¿é—®æƒé‡æ•°æ®æœ¬èº«ï¼ˆé€šå¸¸åªåœ¨åˆå§‹åŒ–æˆ–è°ƒè¯•ç”¨ï¼‰ net[0].weight.data.normal_(0, 0.01) net[0].bias.data.fill_(0) loss = nn.MSELoss() trainer = torch.optim.SGD(net.parameters(), lr=0.03) num_epochs = 3 for epoch in range(num_epochs): for X, y in data_iter: # net(X)å°±æ˜¯ç¥ç»ç½‘ç»œé¢„æµ‹çš„ç»“æœ l = loss(net(X) ,y) # zero_gradæ˜¯æ¸…é™¤ç´¯ç§¯æ¢¯åº¦ trainer.zero_grad() # l.backwardæ˜¯åå‘ä¼ æ’­è‡ªåŠ¨æ±‚å¯¼ l.backward() # stepæ˜¯ç”¨æ¢¯åº¦æ›´æ–°å‚æ•° trainer.step() l = loss(net(features), labels) print(f\u0026#39;epoch {epoch + 1}, loss {l:f}\u0026#39;) w = net[0].weight.data print(\u0026#39;wçš„ä¼°è®¡è¯¯å·®ï¼š\u0026#39;, true_w - w.reshape(true_w.shape)) b = net[0].bias.data print(\u0026#39;bçš„ä¼°è®¡è¯¯å·®ï¼š\u0026#39;, true_b - b) è¿è¡Œç»“æœ ","date":"2025-08-06T14:44:25+08:00","image":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-3.3.-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/index_hu_8cab70e00d02ff6a.jpg","permalink":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-3.3.-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0/","title":"åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ -3.3. çº¿æ€§å›å½’çš„ç®€æ´å®ç°"},{"content":"åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ -3.2. çº¿æ€§å›å½’çš„ä»é›¶å¼€å§‹å®ç° ä»£ç  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 %matplotlib inline import random import torch from d2l import torch as d2l # ç”ŸæˆXå’Œå¸¦å™ªå£°çš„y def synthetic_data(w, b, num_examples): #@save \u0026#34;\u0026#34;\u0026#34;ç”Ÿæˆy=Xw+b+å™ªå£°\u0026#34;\u0026#34;\u0026#34; # ç”Ÿæˆxå½¢çŠ¶ä¸º[num_examples, len(w)]ï¼Œæœ¬æ¬¡ä¸º(1000ï¼Œ2)çš„æœä»æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„æ•°æ® X = torch.normal(0, 1, (num_examples, len(w))) # matmul()å®ç°çŸ©é˜µå’Œå‘é‡çš„ä¹˜æ³• y = torch.matmul(X, w) + b y += torch.normal(0, 0.01, y.shape) # y.reshape((-1, 1))è¡¨ç¤ºå°†yè½¬æ¢ä¸ºä¸€åˆ—å½¢å¼çš„æ•°æ®ï¼Œ-1ä»£è¡¨è‡ªåŠ¨æ ¹æ®åˆ«çš„ç»´åº¦è°ƒæ•´ï¼Œç¡®ä¿yä¸ºäºŒç»´åˆ—å‘é‡ï¼Œä¾¿äºä¸æ¨¡å‹è¾“å‡ºåšå‡æ³• return X, y.reshape((-1, 1)) # åˆå§‹åŒ–wå’Œbçš„çœŸå€¼ true_w = torch.tensor([2, -3.4]) true_b = 4.2 # featureså³ä¸ºä¸Šè¿°å‡½æ•°ç”Ÿæˆçš„Xï¼Œå½¢çŠ¶ä¸º(1000,2) # lableså½¢çŠ¶ä¸º(1000,1) features, labels = synthetic_data(true_w, true_b, 1000) # æŸ¥çœ‹featureså’Œlabelsçš„ç¬¬ä¸€ä¸ªå€¼ print(\u0026#39;featureså’Œlabelsçš„æ ·å­:\u0026#39;) print(\u0026#39;features:\u0026#39;, features[0],\u0026#39;\\nlabel:\u0026#39;, labels[0]) # ç”»å‡ºæ‰€æœ‰æ ·æœ¬ç¬¬2ä¸ªç‰¹å¾ä¸æ ‡ç­¾çš„æ•£ç‚¹å›¾ï¼Œè§‚å¯Ÿç‰¹å¾å’Œæ ‡ç­¾çš„çº¿æ€§å…³ç³» # features[:, (1)].detach().numpy()ä¸­ï¼šdetach()è¡¨ç¤ºä»å¼ é‡ä¸­åˆ†ç¦»å‡ºæ¥æ•°æ®ï¼ˆåç»­ä¸å‚ä¸åå‘ä¼ æ’­ï¼‰ï¼Œ.numpy()è¡¨ç¤ºmatplotlibåªèƒ½æ¥å—numpyæ•°æ® d2l.set_figsize() d2l.plt.scatter(features[:, (1)].detach().numpy(), labels.detach().numpy(), 1); # åˆ†æ‰¹æ¬¡å–å‡ºæ•°æ®çš„å‡½æ•° def data_iter(batch_size, features, labels): num_examples = len(features) indices = list(range(num_examples)) # è¿™äº›æ ·æœ¬æ˜¯éšæœºè¯»å–çš„ï¼Œæ²¡æœ‰ç‰¹å®šçš„é¡ºåº random.shuffle(indices) for i in range(0, num_examples, batch_size): batch_indices = torch.tensor( indices[i: min(i + batch_size, num_examples)]) # yield è®©å‡½æ•°å˜ä¸ºç”Ÿæˆå™¨ï¼Œæ¯æ¬¡è¿”å›ä¸€æ‰¹æ•°æ®ï¼Œæ”¯æŒæŒ‰éœ€é€æ‰¹è¯»å–æ‰€æœ‰æ ·æœ¬ï¼ŒèŠ‚çœå†…å­˜ yield features[batch_indices], labels[batch_indices] batch_size = 10 # æŸ¥çœ‹ç¬¬ä¸€ç»„æ•°æ®çš„æ ·å­ for X, y in data_iter(batch_size, features, labels): print(\u0026#34;ç¬¬ä¸€ç»„æ•°æ®çš„æ ·å­ï¼š\u0026#34;) print(X, \u0026#39;\\n\u0026#39;, y) break # åˆå§‹åŒ–wå’Œbä¸ºéšæœºæ•° w = torch.normal(0, 0.01, size=(2,1), requires_grad=True) b = torch.zeros(1, requires_grad=True) def linreg(X, w, b): #@save \u0026#34;\u0026#34;\u0026#34;çº¿æ€§å›å½’æ¨¡å‹\u0026#34;\u0026#34;\u0026#34; return torch.matmul(X, w) + b def squared_loss(y_hat, y): #@save \u0026#34;\u0026#34;\u0026#34;å‡æ–¹æŸå¤±\u0026#34;\u0026#34;\u0026#34; return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2 def sgd(params, lr, batch_size): #@save \u0026#34;\u0026#34;\u0026#34;å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™\u0026#34;\u0026#34;\u0026#34; with torch.no_grad(): for param in params: param -= lr * param.grad / batch_size # æ¯æ¬¡æ‰‹åŠ¨æ¢¯åº¦æ¸…é›¶ï¼ˆå› ä¸ºæ¯æ¬¡param.gradå±æ€§æ˜¯ PyTorch å¼ é‡çš„ä¸€ä¸ªæˆå‘˜ï¼Œä¸“é—¨ç”¨æ¥å­˜æ”¾å½“å‰å‚æ•°çš„æ¢¯åº¦å€¼ï¼‰ # æ¯æ¬¡è°ƒç”¨ .backward()ï¼ŒPyTorch ä¼šæŠŠç®—å‡ºæ¥çš„æ¢¯åº¦åŠ åˆ°å‚æ•°å·²æœ‰çš„ .grad ä¸Šï¼Œè€Œä¸æ˜¯è¦†ç›– # å¦‚æœä¸æ¸…é›¶ï¼Œæ¯ä¸ª batchã€æ¯ä¸ª mini-batch çš„æ¢¯åº¦å°±ä¼šä¸€ç›´ç´¯åŠ ä¸‹å»ï¼Œæœ€åæ›´æ–°å‚æ•°æ—¶ä¼šæŠŠä¹‹å‰çš„å…¨éƒ¨åŠ ä¸Šï¼Œå¯¼è‡´è®­ç»ƒå‘æ•£æˆ–å®Œå…¨é”™è¯¯ã€‚ param.grad.zero_() lr = 0.03 # è®­ç»ƒè½®æ•° num_epochs = 3 # é€‰ç”¨çº¿æ€§æ¨¡å‹ï¼ˆä¸Šé¢è‡ªå·±å†™å¥½çš„å‡½æ•°ï¼‰ net = linreg # é€‰ç”¨å‡æ–¹è¯¯å·®ï¼ˆä¸Šé¢è‡ªå·±å†™å¥½çš„å‡½æ•°ï¼‰ loss = squared_loss for epoch in range(num_epochs): for X, y in data_iter(batch_size, features, labels): l = loss(net(X, w, b), y) # Xå’Œyçš„å°æ‰¹é‡æŸå¤± # å› ä¸ºlå½¢çŠ¶æ˜¯(batch_size,1)ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæ ‡é‡ã€‚lä¸­çš„æ‰€æœ‰å…ƒç´ è¢«åŠ åˆ°ä¸€èµ·ï¼Œå¹¶ä»¥æ­¤è®¡ç®—å…³äº[w,b]çš„æ¢¯åº¦ï¼ˆå› ä¸ºbackwardè¦æ±‚æ ‡é‡ä½œä¸ºç›®æ ‡ï¼‰ # åŒæ—¶ä¹Ÿå¯¹åº”äº†sgd()å‡½æ•°ä¸­çš„ï¼šparam -= lr * param.grad / batch_sizeçš„â€œ/ batch_sizeâ€ï¼Œå³å…ˆæ±‚å’Œå†é™¤ä»¥æ‰¹å¤§å° # å®Œå…¨ä¹Ÿå¯ä»¥sgd()å‡½æ•°ä¸é™¤ä»¥batch_sizeï¼Œç„¶åæ­¤å¤„sum()æ”¹ä¸ºmean() l.sum().backward() sgd([w, b], lr, batch_size) # ä½¿ç”¨å‚æ•°çš„æ¢¯åº¦æ›´æ–°å‚æ•° with torch.no_grad(): train_l = loss(net(features, w, b), labels) print(f\u0026#39;epoch {epoch + 1}, loss {float(train_l.mean()):f}\u0026#39;) print(f\u0026#39;wçš„ä¼°è®¡è¯¯å·®: {true_w - w.reshape(true_w.shape)}\u0026#39;) print(f\u0026#39;bçš„ä¼°è®¡è¯¯å·®: {true_b - b}\u0026#39;) è¿è¡Œç»“æœ ","date":"2025-08-06T10:34:25+08:00","image":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-3.2.-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0/index_hu_82f287125b34054e.jpg","permalink":"https://example.com/p/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-3.2.-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AE%9E%E7%8E%B0/","title":"åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ -3.2. çº¿æ€§å›å½’çš„ä»é›¶å¼€å§‹å®ç°"},{"content":"åˆ›å»ºä¸€ä¸ªæ·±åº¦å­¦ä¹ è™šæ‹Ÿç¯å¢ƒï¼ˆåŒ…å«d2låŒ…ï¼‰ Step1 åˆ›å»ºä¸€ä¸ªåä¸ºâ€œd2l_envâ€çš„è™šæ‹Ÿç¯å¢ƒå¹¶æ¿€æ´»ï¼ˆæ¨è Python 3.9ï¼Œå…¼å®¹æ€§æœ€ä½³ï¼‰ï¼š\n1 conda create -n d2l_env python=3.9 1 conda activate d2l_env Step2 ä½¿ç”¨pipå®‰è£…pytorchï¼ˆæœ€æ–°ç‰ˆçš„pytorchå·²ç»ä¸æ”¯æŒcondaå®‰è£…ï¼Œæ•…é‡‡ç”¨pipï¼‰ï¼š\n1 pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 Step3 ä½¿ç”¨condaå®‰è£…å¸¸è§ç›¸å…³ä¾èµ–\n1 conda install matplotlib pandas jupyter ipykernel Step4 ä½¿ç”¨pipå®‰è£…æŒ‡å®šç‰ˆæœ¬çš„d2låŒ…ï¼š\n1 pip install d2l==1.0.2 Step5 å°†è¿™ä¸ªè™šæ‹Ÿç¯å¢ƒåŠ å…¥jupyter notebookå†…æ ¸ï¼š\n1 python -m ipykernel install --user --name d2l_env --display-name \u0026#34;Python (d2l_env)\u0026#34; ","date":"2025-08-05T14:44:25+08:00","image":"https://example.com/p/%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E5%8C%85%E5%90%ABd2l%E5%8C%85/index_hu_8485bb27c6ba89e1.jpg","permalink":"https://example.com/p/%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%E5%8C%85%E5%90%ABd2l%E5%8C%85/","title":"åˆ›å»ºä¸€ä¸ªæ·±åº¦å­¦ä¹ è™šæ‹Ÿç¯å¢ƒï¼ˆåŒ…å«d2låŒ…ï¼‰"},{"content":"çº¿æ€§å›å½’è§£æè§£çš„æ¨å¯¼ é—®é¢˜å½¢å¼åŒ– æˆ‘ä»¬è¦åšçš„æ˜¯ï¼š é¦–å…ˆç»™å®šä¸€ç»„æ•°æ® $$ (X,y)\\quadå…¶ä¸­XâˆˆR^{nÃ—d}ï¼ŒyâˆˆR^n $$è¦æ‹Ÿåˆä¸€ä¸ªçº¿æ€§æ¨¡å‹ $$ y=Xw+b $$ æ‰¾åˆ°ä½¿é¢„æµ‹å’ŒçœŸå®å€¼ä¹‹é—´å‡æ–¹è¯¯å·®æœ€å°çš„wå’Œbã€‚\nå…¶æ¬¡ï¼ŒæŠŠæ¯ä¸ªæ ·æœ¬çš„ç‰¹å¾åé¢åŠ ä¸Šä¸€åˆ—å…¨æ˜¯1çš„åˆ—ï¼Œè¿™æ ·å°±å¯ä»¥æŠŠbä½œä¸ºwçš„ä¸€éƒ¨åˆ†å¤„ç†äº†ã€‚\næ‰€ä»¥ï¼Œå¦‚æœåŸå§‹ X æ˜¯ nÃ—d çŸ©é˜µï¼Œæˆ‘ä»¬æ„é€  $$ {X} = [X \\quad \\mathbf{1}] $$å…¶ä¸­ 1æ˜¯ nÃ—1 çš„å…¨1åˆ—å‘é‡ã€‚ æ­¤æ—¶å‚æ•° $$ ~\\tilde{w} ä¸º(d+1) \\times 1å‘é‡ï¼Œæœ€åä¸€ä¸ªå…ƒç´ å°±æ˜¯b $$ å†™å‡ºç›®æ ‡å‡½æ•° çº¿æ€§å›å½’çš„ç›®æ ‡æ˜¯æœ€å°åŒ–æ®‹å·®å¹³æ–¹å’Œï¼ˆMSEï¼‰ï¼š $$ L(\\tilde{w}) = \\| y - \\tilde{X}\\tilde{w} \\|^2 $$ å°†å…¶å†™æˆçŸ©é˜µç›¸ä¹˜çš„å½¢å¼ï¼š $$ L(w)=âˆ¥yâˆ’Xwâˆ¥^2=(yâˆ’Xw) ^âŠ¤(yâˆ’Xw) $$ å±•å¼€ç›®æ ‡å‡½æ•°ä¸ºï¼š $$ L(w)=y^âŠ¤yâˆ’2y^âŠ¤Xw+w^âŠ¤X^âŠ¤Xw $$ å…¶ä¸­ï¼š $$ ğ‘¦^âŠ¤ğ‘¦y^âŠ¤y æ˜¯å¸¸æ•°é¡¹ $$$$ âˆ’2ğ‘¦^âŠ¤ğ‘‹ğ‘¤âˆ’2y^âŠ¤Xw æ˜¯ä¸€æ¬¡é¡¹ $$$$ w^âŠ¤X^âŠ¤Xw æ˜¯äºŒæ¬¡é¡¹ $$ è§£å‡ºè§£æè§£ ç°åœ¨æ¥å¯¹æ¯ä¸€é¡¹åˆ†åˆ«æ±‚å¯¼ï¼š $$ y^\\top yï¼šè·Ÿwæ— å…³ï¼Œå¯¼æ•°æ˜¯0 $$$$ -2y^\\top Xwï¼šå¯¹wæ±‚å¯¼ï¼Œå°±æ˜¯-2X^\\top y $$$$ w^\\top X^\\top Xw ï¼šå¯¹wæ±‚å¯¼ï¼Œå°±æ˜¯ 2X^\\top X w $$ è¿™æ ·ï¼Œæ•´ä¸ªæŸå¤±å‡½æ•°å¯¹wçš„å¯¼æ•°æ˜¯ï¼š $$ \\frac{\\partial L}{\\partial w} = 0 - 2X^\\top y + 2X^\\top X w\\\\= 2X^\\top X w - 2X^\\top y $$ é›¶å…¶ä¸º0ï¼Œå¾— $$ X^âŠ¤Xw=X^âŠ¤y $$ ä¸¤è¾¹å·¦ä¹˜ $$ (ğ‘‹^âŠ¤ğ‘‹)^{âˆ’1} $$ å¾—åˆ° $$ w=(X^âŠ¤X)^{âˆ’1}X^âŠ¤y $$ é™„ çŸ©é˜µç›¸ä¹˜å±•å¼€ï¼š $$ (aâˆ’b)^âŠ¤(aâˆ’b)=a^âŠ¤aâˆ’a^âŠ¤bâˆ’b^âŠ¤a+b^âŠ¤b\\\\å› ä¸ºğ‘^âŠ¤ğ‘å’Œğ‘^âŠ¤ğ‘æ˜¯æ ‡é‡ï¼ˆå®ƒä»¬äº’ä¸ºè½¬ç½®ï¼Œç»“æœç›¸åŒï¼‰ï¼Œæ‰€ä»¥ä¸Šé¢ä¸­é—´ä¸¤é¡¹å¯ä»¥åˆå¹¶ä¸ºï¼š\\\\ğ‘âŠ¤ğ‘âˆ’2ğ‘âŠ¤ğ‘+ğ‘âŠ¤ğ‘ $$ çŸ©é˜µæ±‚å¯¼åŸºç¡€ï¼š $$ \\frac{\\partial}{\\partial w}(w^\\top A w) = 2Aw\\quadï¼ˆå…¶ä¸­ A æ˜¯å¯¹ç§°çŸ©é˜µï¼‰ $$$$ \\frac{\\partial}{\\partial w}(b^\\top w) = b\\quadï¼ˆb æ˜¯å’Œ w ç»´åº¦ç›¸åŒçš„å‘é‡ï¼‰ $$","date":"2025-08-04T14:44:25+08:00","image":"https://example.com/p/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E8%A7%A3%E6%9E%90%E8%A7%A3%E7%9A%84%E6%8E%A8%E5%AF%BC/index_hu_17c525d58159b80.png","permalink":"https://example.com/p/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E8%A7%A3%E6%9E%90%E8%A7%A3%E7%9A%84%E6%8E%A8%E5%AF%BC/","title":"çº¿æ€§å›å½’è§£æè§£çš„æ¨å¯¼"},{"content":"Bellman-Fordç®—æ³•åŸç†åŠPythonå®ç° ç®—æ³•ç®€ä»‹ Bellman-Fordç®—æ³•ä¸»è¦ç”¨äºæ±‚è§£æœ‰å‘å›¾çš„å•æºæœ€çŸ­è·¯å¾„é—®é¢˜ï¼Œä¸è¿ªæ°æ–¯ç‰¹æ‹‰ç®—æ³•ä¸åŒï¼Œä»–å¯ä»¥å¤„ç†å¸¦æœ‰è´Ÿæƒå€¼çš„å›¾ï¼Œå¹¶ä¸”å¯ä»¥æ£€æµ‹å›¾ä¸­æ˜¯å¦æœ‰è´Ÿæƒç¯ï¼ˆè´Ÿæƒç¯æŒ‡çš„æ˜¯ä»æºç‚¹åˆ°æºç‚¹çš„ä¸€ä¸ªç¯ï¼Œå¹¶ä¸”ç¯ä¸Šæƒé‡å’Œä¸ºè´Ÿæ•°ï¼‰ã€‚\nç®—æ³•åŸç† â€‹\tå®ƒçš„åŸºæœ¬æ€æƒ³æ˜¯æ¾å¼›ï¼ˆRelaxationï¼‰æ“ä½œã€‚æ¾å¼›æ˜¯æŒ‡å¯¹äºæ¯ä¸€æ¡è¾¹ï¼ˆuï¼Œvï¼‰ï¼Œå¦‚æœä»æºç‚¹åˆ°é¡¶ç‚¹ u çš„æœ€çŸ­è·¯å¾„è·ç¦»å·²çŸ¥ï¼Œå¹¶ä¸”ä»æºç‚¹åˆ°é¡¶ç‚¹ v çš„è·ç¦»å¯ä»¥é€šè¿‡ç»è¿‡é¡¶ç‚¹ u çš„è·¯å¾„æ¥æ›´æ–°ä¸ºä¸€ä¸ªæ›´å°çš„å€¼ï¼Œé‚£ä¹ˆå°±æ›´æ–°é¡¶ç‚¹ v çš„å½“å‰æœ€çŸ­è·¯å¾„è·ç¦»ã€‚\nâ€‹\tç®—æ³•é‡å¤è¿›è¡Œæ¾å¼›æ“ä½œï¼Œå¯¹äºå›¾ä¸­çš„æ¯ä¸€æ¡è¾¹éƒ½è¿›è¡Œæ£€æŸ¥ï¼Œå°è¯•æ›´æ–°é¡¶ç‚¹çš„æœ€çŸ­è·¯å¾„ä¼°è®¡å€¼ã€‚è¿™ä¸ªè¿‡ç¨‹éœ€è¦è¿›è¡Œ |V| - 1 æ¬¡ï¼ˆ|V| æ˜¯å›¾ä¸­é¡¶ç‚¹çš„æ•°é‡ï¼‰ï¼Œå› ä¸ºåœ¨æœ€åæƒ…å†µä¸‹ï¼Œä¸€ä¸ªé¡¶ç‚¹çš„æœ€çŸ­è·¯å¾„å¯èƒ½éœ€è¦ç»è¿‡æ‰€æœ‰å…¶ä»–é¡¶ç‚¹ã€‚\nâ€‹\tå› æ­¤ç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸º Oï¼ˆ|V|ãƒ»|E|ï¼‰ï¼Œå…¶ä¸­ |V| æ˜¯é¡¶ç‚¹æ•°ï¼Œ|E| æ˜¯è¾¹æ•°ã€‚\nç®—æ³•æµç¨‹ æ­¥éª¤1ï¼šåˆå§‹åŒ– å°†æºç‚¹çš„æœ€çŸ­è·¯å¾„è·ç¦»è®¾ä¸º 0ï¼Œå…¶ä»–æ‰€æœ‰é¡¶ç‚¹çš„æœ€çŸ­è·¯å¾„è·ç¦»è®¾ä¸ºæ— ç©·å¤§ã€‚\næ­¥éª¤2ï¼šåå¤è¿›è¡Œæ¾å¼›æ“ä½œ å¯¹äºæ¯ä¸€æ¡è¾¹ï¼ˆuï¼Œvï¼‰ï¼Œåœ¨ |V| - 1 æ¬¡è¿­ä»£ä¸­ï¼Œå¦‚æœå½“å‰é¡¶ç‚¹ u çš„æœ€çŸ­è·¯å¾„è·ç¦»åŠ ä¸Šè¾¹ï¼ˆuï¼Œvï¼‰çš„æƒé‡å°äºé¡¶ç‚¹ v å½“å‰è®°å½•çš„æœ€çŸ­è·¯å¾„è·ç¦»ï¼Œåˆ™æ›´æ–°é¡¶ç‚¹ v çš„æœ€çŸ­è·¯å¾„è·ç¦»ã€‚\næ­¥éª¤3ï¼šæ£€æµ‹æ˜¯å¦å­˜åœ¨è´Ÿæƒå›è·¯ åœ¨å®Œæˆ |V| - 1 æ¬¡æ¾å¼›æ“ä½œåï¼Œå†å¯¹æ‰€æœ‰è¾¹è¿›è¡Œä¸€æ¬¡æ£€æŸ¥ã€‚å¦‚æœè¿˜èƒ½æ¾å¼›ï¼Œè¯´æ˜å›¾ä¸­å­˜åœ¨ä»æºç‚¹å¯è¾¾çš„è´Ÿæƒå›è·¯ï¼Œæ­¤æ—¶æœ€çŸ­è·¯å¾„ä¸å­˜åœ¨ï¼ˆå› ä¸ºå¯ä»¥æ— é™ç»•è´Ÿæƒå›è·¯æ¥é™ä½è·¯å¾„æƒé‡ï¼‰ã€‚\nPythonå®ç° 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 class Edge: def __init__(self, src, dest, weight): self.src = src self.dest = dest self.weight = weight def bellman_ford(vertices, edges, src): # åˆå§‹åŒ–è·ç¦»æ•°ç»„ï¼Œè·ç¦»æºç‚¹çš„è·ç¦»ä¸ºæ— ç©·å¤§ dist = [float(\u0026#39;inf\u0026#39;)] * (vertices + 1) dist[src] = 0 # æºç‚¹åˆ°è‡ªèº«çš„è·ç¦»ä¸º 0 # è¿›è¡Œ vertices-1 æ¬¡æ¾å¼›æ“ä½œ for _ in range(vertices - 1): updated = False for edge in edges: u = edge.src v = edge.dest weight = edge.weight if dist[u] != float(\u0026#39;inf\u0026#39;) and dist[v] \u0026gt; dist[u] + weight: dist[v] = dist[u] + weight updated = True if not updated: break # å¦‚æœæ²¡æœ‰è¾¹å¯ä»¥æ¾å¼›ï¼Œæå‰é€€å‡º # æ£€æµ‹æ˜¯å¦å­˜åœ¨è´Ÿæƒå›è·¯ has_negative_cycle = False for edge in edges: u = edge.src v = edge.dest weight = edge.weight if dist[u] != float(\u0026#39;inf\u0026#39;) and dist[v] \u0026gt; dist[u] + weight: has_negative_cycle = True break return dist, has_negative_cycle è¾“å…¥ä¸è¾“å‡º è¾“å…¥ä¸ºå›¾çš„é‚»æ¥çŸ©é˜µï¼Œå…¶ä¸­ graph[i][j] è¡¨ç¤ºä»èŠ‚ç‚¹ i åˆ°èŠ‚ç‚¹ j çš„è¾¹çš„æƒé‡ã€‚å¦‚æœèŠ‚ç‚¹ä¹‹é—´æ²¡æœ‰ç›´æ¥çš„è¾¹ï¼Œåˆ™ç”¨ä¸€ä¸ªè¶³å¤Ÿå¤§çš„å€¼ï¼ˆå¦‚ maxï¼‰è¡¨ç¤ºä¸å¯è¾¾ã€‚\nè¾“å‡ºä¸º path æ•°ç»„ï¼Œå…¶ä¸­ path[i] è¡¨ç¤ºä»èµ·ç‚¹åˆ°èŠ‚ç‚¹ i çš„æœ€çŸ­è·¯å¾„ä¸­ï¼Œåˆ°è¾¾èŠ‚ç‚¹ i çš„å‰ä¸€ä¸ªèŠ‚ç‚¹çš„ç´¢å¼•ã€‚å¦‚æœèŠ‚ç‚¹ä¸å¯è¾¾ï¼Œåˆ™ path[i] ä¸º -1\nè‹¥æƒ³é€šè¿‡pathæ•°ç»„å¾—åˆ°ä»èµ·ç‚¹åˆ°æŸä¸ªèŠ‚ç‚¹kçš„è·¯å¾„ï¼Œå¯ç”±å¦‚ä¸‹ä»£ç å®ç°ï¼š\n1 2 3 4 5 6 7 8 9 10 def get_path(path, start_index, target_index): if path[target_index] == -1: return \u0026#34;æ²¡æœ‰è·¯å¾„å¯è¾¾\u0026#34; path_list = [] while target_index != start_index: path_list.append(target_index) target_index = path[target_index] path_list.append(start_index) path_list.reverse() return path_list ä»£ç æµ‹è¯• ä¸»ç¨‹åºæµ‹è¯•ä»£ç ä¸ºï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 if __name__ == \u0026#34;__main__\u0026#34;: # å›¾1çš„é¡¶ç‚¹æ•°ä¸º 5 vertices1 = 5 # å›¾1çš„è¾¹é›†åˆ edges1 = [ Edge(1, 2, 4), Edge(1, 3, 2), Edge(2, 3, 5), Edge(2, 4, 3), Edge(3, 2, -3), Edge(3, 5, 7), Edge(4, 5, 1), Edge(5, 1, 8) ] # æºç‚¹ä¸º 1 src1 = 1 distances1, has_negative_cycle1 = bellman_ford(vertices1, edges1, src1) print(\u0026#34;å›¾1ç¤ºä¾‹ï¼šæ— è´Ÿæƒç¯å›¾\u0026#34;) if has_negative_cycle1: print(\u0026#34;å›¾ä¸­å­˜åœ¨è´Ÿæƒå›è·¯\u0026#34;) else: print(\u0026#34;æºç‚¹ä¸º\u0026#34;, src1, \u0026#34;çš„æœ€çŸ­è·ç¦»ä¸º:\u0026#34;) for i in range(1, vertices1 + 1): print(\u0026#34;åˆ°é¡¶ç‚¹\u0026#34;, i, \u0026#34;çš„è·ç¦»ä¸º:\u0026#34;, distances1[i]) #-------------------------------------åˆ†å‰²çº¿----------------------------------------------- # å›¾2çš„é¡¶ç‚¹æ•°ä¸º 3 vertices2 = 3 edges2 = [ Edge(1, 2, 1), Edge(2, 3, 2), Edge(3, 1, -4) # è¿™æ¡è¾¹å½¢æˆä¸€ä¸ªè´Ÿæƒç¯ ] src2 = 1 distances2, has_negative_cycle2 = bellman_ford(vertices2, edges2, src2) print(\u0026#34;å›¾2ç¤ºä¾‹ï¼šæœ‰è´Ÿæƒç¯å›¾\u0026#34;) if has_negative_cycle2: print(\u0026#34;å›¾ä¸­å­˜åœ¨è´Ÿæƒå›è·¯\u0026#34;) else: print(\u0026#34;æºç‚¹ä¸º\u0026#34;, src2, \u0026#34;çš„æœ€çŸ­è·ç¦»ä¸º:\u0026#34;) for i in range(1, vertices2 + 1): print(\u0026#34;åˆ°é¡¶ç‚¹\u0026#34;, i, \u0026#34;çš„è·ç¦»ä¸º:\u0026#34;, distances2[i]) è¿è¡Œç»“æœä¸ºï¼š\n1 2 3 4 5 6 7 8 9 10 11 E:\\BLOG_article\\Bellman-Ford\\.venv\\Scripts\\python.exe E:\\BLOG_article\\Bellman-Ford\\Bellman-Ford.py å›¾1ç¤ºä¾‹ï¼šæ— è´Ÿæƒç¯å›¾ æºç‚¹ä¸º 1 çš„æœ€çŸ­è·ç¦»ä¸º: åˆ°é¡¶ç‚¹ 1 çš„è·ç¦»ä¸º: 0 åˆ°é¡¶ç‚¹ 2 çš„è·ç¦»ä¸º: -1 åˆ°é¡¶ç‚¹ 3 çš„è·ç¦»ä¸º: 2 åˆ°é¡¶ç‚¹ 4 çš„è·ç¦»ä¸º: 2 åˆ°é¡¶ç‚¹ 5 çš„è·ç¦»ä¸º: 3 å›¾2ç¤ºä¾‹ï¼šæœ‰è´Ÿæƒç¯å›¾ å›¾ä¸­å­˜åœ¨è´Ÿæƒå›è·¯ å®Œæ•´ä»£ç  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 class Edge: def __init__(self, src, dest, weight): self.src = src self.dest = dest self.weight = weight def bellman_ford(vertices, edges, src): # åˆå§‹åŒ–è·ç¦»æ•°ç»„ï¼Œè·ç¦»æºç‚¹çš„è·ç¦»ä¸ºæ— ç©·å¤§ dist = [float(\u0026#39;inf\u0026#39;)] * (vertices + 1) dist[src] = 0 # æºç‚¹åˆ°è‡ªèº«çš„è·ç¦»ä¸º 0 # è¿›è¡Œ vertices-1 æ¬¡æ¾å¼›æ“ä½œ for _ in range(vertices - 1): updated = False for edge in edges: u = edge.src v = edge.dest weight = edge.weight if dist[u] != float(\u0026#39;inf\u0026#39;) and dist[v] \u0026gt; dist[u] + weight: dist[v] = dist[u] + weight updated = True if not updated: break # å¦‚æœæ²¡æœ‰è¾¹å¯ä»¥æ¾å¼›ï¼Œæå‰é€€å‡º # æ£€æµ‹æ˜¯å¦å­˜åœ¨è´Ÿæƒå›è·¯ has_negative_cycle = False for edge in edges: u = edge.src v = edge.dest weight = edge.weight if dist[u] != float(\u0026#39;inf\u0026#39;) and dist[v] \u0026gt; dist[u] + weight: has_negative_cycle = True break return dist, has_negative_cycle if __name__ == \u0026#34;__main__\u0026#34;: # å›¾1çš„é¡¶ç‚¹æ•°ä¸º 5 vertices1 = 5 # å›¾1çš„è¾¹é›†åˆ edges1 = [ Edge(1, 2, 4), Edge(1, 3, 2), Edge(2, 3, 5), Edge(2, 4, 3), Edge(3, 2, -3), Edge(3, 5, 7), Edge(4, 5, 1), Edge(5, 1, 8) ] # æºç‚¹ä¸º 1 src1 = 1 distances1, has_negative_cycle1 = bellman_ford(vertices1, edges1, src1) print(\u0026#34;å›¾1ç¤ºä¾‹ï¼šæ— è´Ÿæƒç¯å›¾\u0026#34;) if has_negative_cycle1: print(\u0026#34;å›¾ä¸­å­˜åœ¨è´Ÿæƒå›è·¯\u0026#34;) else: print(\u0026#34;æºç‚¹ä¸º\u0026#34;, src1, \u0026#34;çš„æœ€çŸ­è·ç¦»ä¸º:\u0026#34;) for i in range(1, vertices1 + 1): print(\u0026#34;åˆ°é¡¶ç‚¹\u0026#34;, i, \u0026#34;çš„è·ç¦»ä¸º:\u0026#34;, distances1[i]) #-------------------------------------åˆ†å‰²çº¿----------------------------------------------- # å›¾2çš„é¡¶ç‚¹æ•°ä¸º 3 vertices2 = 3 edges2 = [ Edge(1, 2, 1), Edge(2, 3, 2), Edge(3, 1, -4) # è¿™æ¡è¾¹å½¢æˆä¸€ä¸ªè´Ÿæƒç¯ ] src2 = 1 distances2, has_negative_cycle2 = bellman_ford(vertices2, edges2, src2) print(\u0026#34;å›¾2ç¤ºä¾‹ï¼šæœ‰è´Ÿæƒç¯å›¾\u0026#34;) if has_negative_cycle2: print(\u0026#34;å›¾ä¸­å­˜åœ¨è´Ÿæƒå›è·¯\u0026#34;) else: print(\u0026#34;æºç‚¹ä¸º\u0026#34;, src2, \u0026#34;çš„æœ€çŸ­è·ç¦»ä¸º:\u0026#34;) for i in range(1, vertices2 + 1): print(\u0026#34;åˆ°é¡¶ç‚¹\u0026#34;, i, \u0026#34;çš„è·ç¦»ä¸º:\u0026#34;, distances2[i]) ","date":"2025-04-26T14:44:25+08:00","image":"https://example.com/p/bellman-ford%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%8F%8Apython%E5%AE%9E%E7%8E%B0/index_hu_446bb884ffc0e559.png","permalink":"https://example.com/p/bellman-ford%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%8F%8Apython%E5%AE%9E%E7%8E%B0/","title":"Bellman-Fordç®—æ³•åŸç†åŠPythonå®ç°"},{"content":"A*ç®—æ³•åŸç†åŠPythonå®ç° ç®—æ³•ç®€ä»‹ A*ç®—æ³•æ˜¯ä¸€ç§ç”¨äºæ±‚è§£æœ€çŸ­è·¯å¾„é—®é¢˜çš„å¯å‘å¼æœç´¢ç®—æ³•ï¼Œå¹¿æ³›åº”ç”¨äºæœºå™¨äººè·¯å¾„è§„åˆ’ã€æ¸¸æˆåœ°å›¾å¯»è·¯ç­‰åœºæ™¯ã€‚ä¸ Dijkstra ç®—æ³•ä¸åŒï¼ŒA* ç®—æ³•ç»“åˆäº†å®é™…è·¯å¾„ä»£ä»·å’Œå¯å‘å¼ä¼°è®¡ï¼Œä»è€Œèƒ½æ›´é«˜æ•ˆåœ°æ‰¾åˆ°ä»èµ·ç‚¹åˆ°ç»ˆç‚¹çš„æœ€ä¼˜è·¯å¾„ã€‚\nç®—æ³•åŸç† A*ç®—æ³•åŸºäºä»¥ä¸‹è¯„ä»·å‡½æ•°è¿›è¡ŒèŠ‚ç‚¹é€‰æ‹©ï¼š\n1 f(n) = g(n) + h(n) g(n)ï¼šä»èµ·ç‚¹åˆ°å½“å‰èŠ‚ç‚¹ n çš„å®é™…è·¯å¾„ä»£ä»· h(n)ï¼šä»å½“å‰èŠ‚ç‚¹ n åˆ°ç›®æ ‡èŠ‚ç‚¹çš„å¯å‘å¼ä¼°è®¡ï¼ˆé€šå¸¸ä½¿ç”¨æ›¼å“ˆé¡¿è·ç¦»ï¼‰ f(n)ï¼šæ€»ä»£ä»·å‡½æ•°ï¼Œè¡¨ç¤ºå½“å‰è·¯å¾„çš„ä¼˜åŠ£ç¨‹åº¦ é€šè¿‡ä¼˜å…ˆæ‰©å±• f(n) æœ€å°çš„èŠ‚ç‚¹ï¼ŒA*ç®—æ³•åœ¨ä¿è¯æœ€ä¼˜æ€§çš„åŒæ—¶æé«˜äº†æœç´¢æ•ˆç‡ã€‚\næ›¼å“ˆé¡¿è·ç¦» A*ç®—æ³•ä¸­å¸¸ç”¨çš„å¯å‘å‡½æ•°ä¹‹ä¸€æ˜¯æ›¼å“ˆé¡¿è·ç¦»ï¼ˆManhattan Distanceï¼‰ï¼Œé€‚ç”¨äºåªèƒ½æ²¿ç½‘æ ¼ä¸Šä¸‹å·¦å³ç§»åŠ¨çš„æƒ…å†µã€‚\nå®ƒçš„è®¡ç®—æ–¹å¼ä¸ºï¼š\n1 2 å¤åˆ¶ç¼–è¾‘ h(n) = |xâ‚ - xâ‚‚| + |yâ‚ - yâ‚‚| å…¶ä¸­ (xâ‚, yâ‚) æ˜¯å½“å‰èŠ‚ç‚¹çš„åæ ‡ï¼Œ(xâ‚‚, yâ‚‚) æ˜¯ç›®æ ‡èŠ‚ç‚¹çš„åæ ‡ã€‚\nè¿™ç§è·ç¦»è®¡ç®—æ–¹å¼ç±»ä¼¼åœ¨åŸå¸‚è¡—åŒºä¸­æ²¿è¡—é“èµ°è·¯ï¼Œä¸èƒ½ç©¿å¢™æˆ–æ–œç€èµ°ï¼Œæ•…ç§°ä¸ºâ€œæ›¼å“ˆé¡¿â€â€”â€”å¾—åäºçº½çº¦æ›¼å“ˆé¡¿çš„æ£‹ç›˜æ ¼è¡—é“å¸ƒå±€ã€‚\nç®—æ³•æµç¨‹ æ­¥éª¤1ï¼šåˆå§‹åŒ– åˆå§‹åŒ–ä¸‰ä¸ªæ ¸å¿ƒæ•°ç»„ï¼š\ngæ•°ç»„ï¼šè®°å½•ä»èµ·ç‚¹åˆ°å½“å‰èŠ‚ç‚¹çš„æœ€å°ä»£ä»·ï¼Œåˆå§‹å…¨éƒ¨ä¸º âˆï¼Œèµ·ç‚¹ä¸º 0 hæ•°ç»„ï¼šè®°å½•å½“å‰èŠ‚ç‚¹åˆ°ç›®æ ‡èŠ‚ç‚¹çš„å¯å‘å¼ä¼°å€¼ fæ•°ç»„ï¼šè®°å½•æ€»ä»£ä»·ï¼Œf = g + h open_listï¼šä¼˜å…ˆé˜Ÿåˆ—ï¼ˆå°é¡¶å †ï¼‰ï¼Œç”¨äºé€‰æ‹©å½“å‰ä»£ä»·æœ€å°çš„èŠ‚ç‚¹ closed_listï¼šå·²è®¿é—®èŠ‚ç‚¹é›†åˆï¼Œé¿å…é‡å¤æ‰©å±• parentå­—å…¸ï¼šè®°å½•æ¯ä¸ªèŠ‚ç‚¹çš„å‰é©±èŠ‚ç‚¹ æ­¥éª¤2ï¼šé€‰æ‹©få€¼æœ€å°çš„èŠ‚ç‚¹ ä» open_list ä¸­å–å‡º f(n) æœ€å°çš„èŠ‚ç‚¹ï¼Œä½œä¸ºå½“å‰å¤„ç†èŠ‚ç‚¹ã€‚\næ­¥éª¤3ï¼šåˆ¤æ–­æ˜¯å¦åˆ°è¾¾ç›®æ ‡èŠ‚ç‚¹ è‹¥å½“å‰èŠ‚ç‚¹ä¸ºç›®æ ‡èŠ‚ç‚¹ï¼Œåˆ™è¯´æ˜è·¯å¾„å·²æ‰¾åˆ°ï¼Œè°ƒç”¨ seek_path æ–¹æ³•å›æº¯è·¯å¾„ã€‚\næ­¥éª¤4ï¼šæ‰©å±•é‚»å±…èŠ‚ç‚¹ è·å–å››ä¸ªæ–¹å‘çš„å¯é€šè¡Œé‚»å±…èŠ‚ç‚¹ï¼ˆä¸Šä¸‹å·¦å³ï¼‰ å¯¹æ¯ä¸ªé‚»å±…ï¼Œè®¡ç®—æ–°çš„ gã€hã€f å€¼ è‹¥è¯¥è·¯å¾„æ›´ä¼˜ï¼Œåˆ™æ›´æ–°é‚»å±…èŠ‚ç‚¹çš„ä»£ä»·ä¿¡æ¯å¹¶åŠ å…¥ open_list Pythonå®ç° 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 import heapq import matplotlib.pyplot as plt import numpy as np class AStar: def __init__(self, grid, start, goal): self.grid = grid self.start = start self.goal = goal self.rows = len(grid) self.cols = len(grid[0]) self.open_list = [] self.closed_list = set() self.f = np.full((self.rows, self.cols), np.inf) self.g = np.full((self.rows, self.cols), np.inf) self.h = np.full((self.rows, self.cols), 0) self.parent = {} def seek_heuristic(self, x, y): return abs(self.goal[0] - x) + abs(self.goal[1] - y) def seek_neighborhood(self, x, y): directions = [(0, 1), (0, -1), (1, 0), (-1, 0)] neighbors = [] for dx, dy in directions: if 0 \u0026lt;= x + dx \u0026lt; self.rows and 0 \u0026lt;= y + dy \u0026lt; self.cols and self.grid[x + dx][y + dy] == 0: neighbors.append((x + dx, y + dy)) return neighbors def run(self): self.g[self.start[0], self.start[1]] = 0 self.h[self.start[0], self.start[1]] = self.seek_heuristic(*self.start) self.f[self.start[0], self.start[1]] = self.g[self.start[0], self.start[1]] + self.h[self.start[0], self.start[1]] heapq.heappush(self.open_list, (self.f[self.start[0], self.start[1]], self.start)) while self.open_list: _, current_node = heapq.heappop(self.open_list) if current_node == self.goal: return self.seek_path() self.closed_list.add(current_node) for neighbor in self.seek_neighborhood(*current_node): if neighbor in self.closed_list: continue current_g = self.g[current_node[0], current_node[1]] + 1 if neighbor not in self.parent or current_g \u0026lt; self.g[neighbor[0], neighbor[1]]: self.parent[neighbor] = current_node self.g[neighbor[0], neighbor[1]] = current_g self.h[neighbor[0], neighbor[1]] = self.seek_heuristic(*neighbor) self.f[neighbor[0], neighbor[1]] = self.g[neighbor[0], neighbor[1]] + self.h[neighbor[0], neighbor[1]] if neighbor not in [node[1] for node in self.open_list]: heapq.heappush(self.open_list, (self.f[neighbor[0], neighbor[1]], neighbor)) return None def seek_path(self): path = [] current_node = self.goal while current_node != self.start: path.append(current_node) current_node = self.parent[current_node] path.append(self.start) path.reverse() return path å¯è§†åŒ–è·¯å¾„ 1 2 3 4 5 6 7 8 9 10 def plot_path(grid, path): plt.figure(figsize=(8, 8)) plt.imshow(grid, cmap=\u0026#39;Greys\u0026#39;, origin=\u0026#39;lower\u0026#39;) path_x, path_y = zip(*path) plt.plot(path_y, path_x, color=\u0026#39;r\u0026#39;, linewidth=2, marker=\u0026#39;o\u0026#39;) plt.scatter(path_y[0], path_x[0], color=\u0026#39;g\u0026#39;, s=100, label=\u0026#39;Start\u0026#39;) plt.scatter(path_y[-1], path_x[-1], color=\u0026#39;b\u0026#39;, s=100, label=\u0026#39;Goal\u0026#39;) plt.legend() plt.title(\u0026#34;A* Pathfinding\u0026#34;) plt.show() ä»£ç æµ‹è¯• ä¸»ç¨‹åºæµ‹è¯•ä»£ç ä¸ºï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 if __name__ == \u0026#34;__main__\u0026#34;: grid = [ [0, 0, 0, 0, 0], [1, 1, 1, 1, 0], [0, 0, 0, 0, 0], [0, 1, 1, 1, 0], [0, 0, 0, 0, 0] ] start = (0, 0) goal = (4, 4) astar = AStar(grid, start, goal) path = astar.run() if path: print(\u0026#34;è·¯å¾„ä¸ºï¼š\u0026#34;, path) plot_path(grid, path) else: print(\u0026#34;æœªæ‰¾åˆ°è·¯å¾„\u0026#34;) è¿è¡Œç»“æœä¸ºï¼š\n1 è·¯å¾„ä¸ºï¼š [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 4), (2, 4), (2, 3), (2, 2), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3), (4, 4)] å®Œæ•´ä»£ç  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 import heapq import matplotlib.pyplot as plt import numpy as np class AStar: def __init__(self, grid, start, goal): self.grid=grid self.start=start self.goal=goal self.rows=len(grid) self.cols=len(grid[0]) self.open_list=[] self.closed_list=set() self.f=np.full((self.rows,self.cols),np.inf) self.g=np.full((self.rows,self.cols),np.inf) self.h=np.full((self.rows,self.cols),0) self.parent={} def seek_heuristic(self,x,y): return abs(self.goal[0]-x)+abs(self.goal[1]-y) def seek_neighborhood(self,x,y): directions=[(0,1),(0,-1),(1,0),(-1,0)] neighbors=[] for dx,dy in directions: if 0\u0026lt;=x+dx\u0026lt;self.rows and 0\u0026lt;=y+dy\u0026lt;self.cols and self.grid[x+dx][y+dy]==0: neighbors.append((x+dx,y+dy)) return neighbors def run(self): # åˆå§‹åŒ–èµ·ç‚¹ self.g[self.start[0], self.start[1]] = 0 self.h[self.start[0], self.start[1]] = self.seek_heuristic(self.start[0], self.start[1]) self.f[self.start[0], self.start[1]] = self.g[self.start[0], self.start[1]]+self.h[self.start[0], self.start[1]] heapq.heappush(self.open_list,(self.f[self.start[0], self.start[1]],self.start)) while self.open_list: _,current_node=heapq.heappop(self.open_list) if current_node==self.goal: return self.seek_path() self.closed_list.add(current_node) for neighbor in self.seek_neighborhood(current_node[0],current_node[1]): if neighbor in self.closed_list: continue current_g=self.g[current_node[0],current_node[1]] + 1 if neighbor not in self.parent or current_g\u0026lt;self.g[neighbor[0],neighbor[1]]: self.parent[neighbor]=current_node self.g[neighbor[0],neighbor[1]] = current_g self.h[neighbor[0],neighbor[1]] = self.seek_heuristic(neighbor[0],neighbor[1]) self.f[neighbor[0],neighbor[1]] = self.g[neighbor[0],neighbor[1]] + self.h[neighbor[0],neighbor[1]] if neighbor not in [node[1] for node in self.open_list]: heapq.heappush(self.open_list,(self.f[neighbor[0],neighbor[1]],neighbor)) return None def seek_path(self): path=[] current_node=self.goal while current_node!=self.start: path.append(current_node) current_node=self.parent[current_node] path.append(self.start) path.reverse() return path def plot_path(grid,path): plt.figure(figsize=(8, 8)) plt.imshow(grid, cmap=\u0026#39;Greys\u0026#39;, origin=\u0026#39;lower\u0026#39;) path_x, path_y = zip(*path) plt.plot(path_y, path_x, color=\u0026#39;r\u0026#39;, linewidth=2, marker=\u0026#39;o\u0026#39;) plt.scatter(path_y[0], path_x[0], color=\u0026#39;g\u0026#39;, s=100, label=\u0026#39;Start\u0026#39;) plt.scatter(path_y[-1], path_x[-1], color=\u0026#39;b\u0026#39;, s=100, label=\u0026#39;Goal\u0026#39;) plt.legend() plt.title(\u0026#34;A* Pathfinding\u0026#34;) plt.show() # æµ‹è¯• if __name__ == \u0026#34;__main__\u0026#34;: grid = [ [0, 0, 0, 0, 0], [1, 1, 1, 1, 0], [0, 0, 0, 0, 0], [0, 1, 1, 1, 0], [0, 0, 0, 0, 0] ] start = (0, 0) goal = (4, 4) astar = AStar(grid, start, goal) path = astar.run() if path: print(\u0026#34;Path found:\u0026#34;, path) plot_path(grid, path) else: print(\u0026#34;No path found\u0026#34;) ","date":"2025-04-22T14:44:25+08:00","image":"https://example.com/p/a%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%8F%8Apython%E5%AE%9E%E7%8E%B0/index_hu_1b349549350c032d.jpg","permalink":"https://example.com/p/a%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%8F%8Apython%E5%AE%9E%E7%8E%B0/","title":"A*ç®—æ³•åŸç†åŠPythonå®ç°"},{"content":"è¿ªæ°æ–¯ç‰¹æ‹‰ç®—æ³•åŸç†åŠPythonå®ç° ç®—æ³•ç®€ä»‹ è¿ªæ°æ–¯ç‰¹æ‹‰ï¼ˆDijkstraï¼‰ç®—æ³•ä¸»è¦ç”¨äºæ±‚è§£æ²¡æœ‰è´Ÿå€¼çš„æœ‰å‘å›¾çš„å•æºæœ€çŸ­è·¯å¾„é—®é¢˜ã€‚\nç®—æ³•åŸç† ç®—æ³•åŸºäºè´ªå¿ƒç­–ç•¥ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡é€æ­¥æ‰©å±•å·²çŸ¥æœ€çŸ­è·¯å¾„çš„é›†åˆæ¥æ‰¾åˆ°ä»èµ·ç‚¹åˆ°æ‰€æœ‰å…¶ä»–èŠ‚ç‚¹çš„æœ€çŸ­è·¯å¾„ã€‚\nç®—æ³•æµç¨‹ æ­¥éª¤1ï¼šåˆå§‹åŒ– åˆå§‹åŒ–costæ•°ç»„ï¼Œpathæ•°ç»„å’Œvisitedæ•°ç»„\ncostæ•°ç»„ å¯¹äºcostæ•°ç»„ï¼Œåˆå§‹å…¨éƒ¨è®¾ç½®ä¸ºæœ€å¤§å€¼ï¼Œèµ·ç‚¹èŠ‚ç‚¹è®¾ç½®ä¸º0\n1 costæ•°ç»„ï¼šcost[i]è¡¨ç¤ºä»start_indexåˆ°iå·å…ƒç´ çš„æœ€å°èŠ±è´¹ pathæ•°ç»„ å¯¹äºpathæ•°ç»„ï¼Œåˆå§‹å…¨éƒ¨è®¾ç½®ä¸º-1ï¼Œè¡¨ç¤ºä¸å¯è¾¾ï¼Œèµ·ç‚¹èŠ‚ç‚¹è®¾ç½®ä¸ºèµ·ç‚¹èŠ‚ç‚¹çš„ä½ç½®\n1 pathæ•°ç»„ï¼špath[i]è¡¨ç¤ºä»start_indexåˆ°iå·å…ƒç´ çš„æœ€çŸ­è·¯å¾„ä¸­ï¼Œåˆ°è¾¾iå·å…ƒç´ çš„å‰ä¸€ä¸ªå…ƒç´ ç´¢å¼•ä¸ºpath[i]ï¼ˆå³æƒ³è¦ä»¥æœ€å°èŠ±è´¹åˆ°è¾¾iå·å…ƒç´ ï¼Œéœ€è¦é€šè¿‡path[i]å·å…ƒç´ ï¼‰ visitedæ•°ç»„ å¯¹äºvisitedæ•°ç»„ï¼Œåˆå§‹å…¨éƒ¨è®¾ç½®ä¸º0ï¼Œèµ·ç‚¹èŠ‚ç‚¹è®¾ç½®ä¸º1\n1 visitedæ•°ç»„ï¼švisited[i]è¡¨ç¤ºiå·å…ƒç´ æ˜¯å¦è¢«è®¿é—®è¿‡ï¼ˆvisited[i]==1è¡¨ç¤ºå·²ç»æ‰¾åˆ°äº†æœ€ä¼˜è·¯å¾„ï¼‰ æ­¥éª¤2ï¼šæ‰¾åˆ°ä¸‹ä¸€ä¸ªâ€œæœ€ä¼˜èŠ‚ç‚¹â€ â€œæœ€ä¼˜èŠ‚ç‚¹â€æŒ‡çš„æ˜¯ä»å½“å‰èŠ‚ç‚¹åˆ°å…¶ä»–èŠ‚ç‚¹ä¸­ä»£ä»·æœ€å°çš„èŠ‚ç‚¹ï¼Œè¿™ä¸ªâ€œæœ€ä¼˜èŠ‚ç‚¹â€ä¹Ÿä¼šä½œä¸ºä¸‹ä¸€æ¬¡è¿­ä»£çš„â€œå½“å‰èŠ‚ç‚¹â€\næ­¥éª¤3ï¼šæ›´æ–°visitedæ•°ç»„ å°†æ‰¾åˆ°çš„æœ€ä¼˜èŠ‚ç‚¹è®¾ç½®æˆâ€œå·²è®¿é—®â€çŠ¶æ€ï¼Œå³å°†å…¶è®¾ç½®ä¸ºâ€œå½“å‰èŠ‚ç‚¹â€\næ­¥éª¤4ï¼šæ›´æ–°â€œæœ€ä¼˜èŠ‚ç‚¹é™„è¿‘èŠ‚ç‚¹çš„æ•°æ®â€ è®¿é—®æ‰€æœ‰è¿˜æœªè¢«è®¿é—®çš„èŠ‚ç‚¹ï¼Œè‹¥ä»å½“å‰èŠ‚ç‚¹â€œåˆ°æ­¤èŠ‚ç‚¹çš„ä»£ä»·æ›´å°ï¼Œåˆ™æ›´æ–°costæ•°ç»„å’Œpathæ•°ç»„\nPythonå®ç° 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def dijkstra(graph,start_index,max): # åˆå§‹åŒ–cost,path,visitedæ•°ç»„ # costæ•°ç»„ï¼šcost[i]è¡¨ç¤ºä»start_indexåˆ°iå·å…ƒç´ çš„æœ€å°èŠ±è´¹ cost=[max]*len(graph) cost[start_index] = 0 # pathæ•°ç»„ï¼špath[i]è¡¨ç¤ºä»start_indexåˆ°iå·å…ƒç´ çš„æœ€çŸ­è·¯å¾„ä¸­ï¼Œåˆ°è¾¾iå·å…ƒç´ çš„å‰ä¸€ä¸ªå…ƒç´ ç´¢å¼•ä¸ºpath[i]ï¼ˆå³æƒ³è¦ä»¥æœ€å°èŠ±è´¹åˆ°è¾¾iå·å…ƒç´ ï¼Œéœ€è¦é€šè¿‡path[i]å·å…ƒç´ ï¼‰ path = [-1] * len(graph) path[start_index] = start_index # visitedæ•°ç»„ï¼švisited[i]è¡¨ç¤ºiå·å…ƒç´ æ˜¯å¦è¢«è®¿é—®è¿‡ï¼ˆå·²ç»æ‰¾åˆ°äº†æœ€ä¼˜è·¯å¾„ï¼‰ visited=[0]*len(graph) visited[start_index]=1 for i in range(len(graph)): if(visited[i]==0): cost[i]=graph[start_index][i] # path[i]=-1è¡¨ç¤ºä¸å¯è¾¾ path[i]=(start_index if(cost[i]\u0026lt;max) else -1) # ä¸»ä½“ä»£ç  for i in range(1,len(graph)): cur_index=-1 min_cost=max # æ‰¾åˆ°ä¸‹ä¸€æ­¥ä»£ä»·æœ€å°çš„èŠ‚ç‚¹ for j in range(len(graph)): if(visited[j]==0): if(cost[j]\u0026lt;min_cost): min_cost=cost[j] cur_index=j # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯è®¿é—®çš„èŠ‚ç‚¹ï¼Œé€€å‡ºå¾ªç¯ if cur_index==-1: break # æ ‡è®°ä¸‹ä¸€æ­¥ä»£ä»·æœ€å°çš„èŠ‚ç‚¹ä¸ºå·²è®¿é—®çš„èŠ‚ç‚¹ï¼ˆå½“å‰èŠ‚ç‚¹ï¼‰ visited[cur_index]=1 # ä¾æ®æ‰¾åˆ°çš„ä¸‹ä¸€æ­¥ä»£ä»·æœ€å°çš„èŠ‚ç‚¹cur_indexæ›´æ–°å…¶é™„è¿‘ä¸€åœˆçš„èŠ‚ç‚¹æ•°æ® for k in range(len(graph)): if(visited[k]==0): if(cost[cur_index]+graph[cur_index][k]\u0026lt;cost[k]): cost[k]=cost[cur_index]+graph[cur_index][k] path[k]=cur_index return path è¾“å…¥ä¸è¾“å‡º è¾“å…¥ä¸ºå›¾çš„é‚»æ¥çŸ©é˜µï¼Œå…¶ä¸­ graph[i][j] è¡¨ç¤ºä»èŠ‚ç‚¹ i åˆ°èŠ‚ç‚¹ j çš„è¾¹çš„æƒé‡ã€‚å¦‚æœèŠ‚ç‚¹ä¹‹é—´æ²¡æœ‰ç›´æ¥çš„è¾¹ï¼Œåˆ™ç”¨ä¸€ä¸ªè¶³å¤Ÿå¤§çš„å€¼ï¼ˆå¦‚ maxï¼‰è¡¨ç¤ºä¸å¯è¾¾ã€‚\nè¾“å‡ºä¸º path æ•°ç»„ï¼Œå…¶ä¸­ path[i] è¡¨ç¤ºä»èµ·ç‚¹åˆ°èŠ‚ç‚¹ i çš„æœ€çŸ­è·¯å¾„ä¸­ï¼Œåˆ°è¾¾èŠ‚ç‚¹ i çš„å‰ä¸€ä¸ªèŠ‚ç‚¹çš„ç´¢å¼•ã€‚å¦‚æœèŠ‚ç‚¹ä¸å¯è¾¾ï¼Œåˆ™ path[i] ä¸º -1\nè‹¥æƒ³é€šè¿‡pathæ•°ç»„å¾—åˆ°ä»èµ·ç‚¹åˆ°æŸä¸ªèŠ‚ç‚¹kçš„è·¯å¾„ï¼Œå¯ç”±å¦‚ä¸‹ä»£ç å®ç°ï¼š\n1 2 3 4 5 6 7 8 9 10 def get_path(path, start_index, target_index): if path[target_index] == -1: return \u0026#34;æ²¡æœ‰è·¯å¾„å¯è¾¾\u0026#34; path_list = [] while target_index != start_index: path_list.append(target_index) target_index = path[target_index] path_list.append(start_index) path_list.reverse() return path_list ä»£ç æµ‹è¯• ä¸»ç¨‹åºæµ‹è¯•ä»£ç ä¸ºï¼š\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 if __name__==\u0026#34;__main__\u0026#34;: max=2**31-1 graph=[ [max, max, 10, max, 30, 100], [max, max, 5, max, max, max], [max, max, max, 50, max, max], [max, max, max, max, max, 10], [max, max, max, 20, max, 60], [max, max, max, max, max, max], ] result=dijkstra(graph,0,max) print(\u0026#34;æœ€çŸ­è·¯å¾„çš„å‰é©±èŠ‚ç‚¹æ•°ç»„ä¸ºï¼š\u0026#34;,result) target_index = 5 path_to_target = get_path(result, 0, target_index) print(f\u0026#34;ä»èµ·ç‚¹åˆ°ç›®æ ‡èŠ‚ç‚¹ {target_index} çš„è·¯å¾„ä¸ºï¼š\u0026#34;, path_to_target) è¿è¡Œç»“æœä¸ºï¼š\n1 2 3 E:\\BLOG_article\\Dijkstra\\.venv\\Scripts\\python.exe E:\\BLOG_article\\Dijkstra\\Dijkstra.py æœ€çŸ­è·¯å¾„çš„å‰é©±èŠ‚ç‚¹æ•°ç»„ä¸ºï¼š [0, -1, 0, 4, 0, 3] ä»èµ·ç‚¹åˆ°ç›®æ ‡èŠ‚ç‚¹ 5 çš„è·¯å¾„ä¸ºï¼š [0, 4, 3, 5] å®Œæ•´ä»£ç  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 def dijkstra(graph,start_index,max): # åˆå§‹åŒ–cost,path,visitedæ•°ç»„ # costæ•°ç»„ï¼šcost[i]è¡¨ç¤ºä»start_indexåˆ°iå·å…ƒç´ çš„æœ€å°èŠ±è´¹ cost=[max]*len(graph) cost[start_index] = 0 # pathæ•°ç»„ï¼špath[i]è¡¨ç¤ºä»start_indexåˆ°iå·å…ƒç´ çš„æœ€çŸ­è·¯å¾„ä¸­ï¼Œåˆ°è¾¾iå·å…ƒç´ çš„å‰ä¸€ä¸ªå…ƒç´ ç´¢å¼•ä¸ºpath[i]ï¼ˆå³æƒ³è¦ä»¥æœ€å°èŠ±è´¹åˆ°è¾¾iå·å…ƒç´ ï¼Œéœ€è¦é€šè¿‡path[i]å·å…ƒç´ ï¼‰ path = [-1] * len(graph) path[start_index] = start_index # visitedæ•°ç»„ï¼švisited[i]è¡¨ç¤ºiå·å…ƒç´ æ˜¯å¦è¢«è®¿é—®è¿‡ï¼ˆå·²ç»æ‰¾åˆ°äº†æœ€ä¼˜è·¯å¾„ï¼‰ visited=[0]*len(graph) visited[start_index]=1 for i in range(len(graph)): if(visited[i]==0): cost[i]=graph[start_index][i] # path[i]=-1è¡¨ç¤ºä¸å¯è¾¾ path[i]=(start_index if(cost[i]\u0026lt;max) else -1) # ä¸»ä½“ä»£ç  for i in range(1,len(graph)): cur_index=-1 min_cost=max # æ‰¾åˆ°ä¸‹ä¸€æ­¥ä»£ä»·æœ€å°çš„èŠ‚ç‚¹ for j in range(len(graph)): if(visited[j]==0): if(cost[j]\u0026lt;min_cost): min_cost=cost[j] cur_index=j # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯è®¿é—®çš„èŠ‚ç‚¹ï¼Œé€€å‡ºå¾ªç¯ if cur_index==-1: break # æ ‡è®°ä¸‹ä¸€æ­¥ä»£ä»·æœ€å°çš„èŠ‚ç‚¹ä¸ºå·²è®¿é—®çš„èŠ‚ç‚¹ visited[cur_index]=1 # ä¾æ®æ‰¾åˆ°çš„ä¸‹ä¸€æ­¥ä»£ä»·æœ€å°çš„èŠ‚ç‚¹cur_indexæ›´æ–°å…¶é™„è¿‘ä¸€åœˆçš„èŠ‚ç‚¹æ•°æ® for k in range(len(graph)): if(visited[k]==0): if(cost[cur_index]+graph[cur_index][k]\u0026lt;cost[k]): cost[k]=cost[cur_index]+graph[cur_index][k] path[k]=cur_index return path def get_path(path, start_index, target_index): if path[target_index] == -1: return \u0026#34;No path exists\u0026#34; path_list = [] while target_index != start_index: path_list.append(target_index) target_index = path[target_index] path_list.append(start_index) path_list.reverse() return path_list if __name__==\u0026#34;__main__\u0026#34;: max=2**31-1 graph=[ [max, max, 10, max, 30, 100], [max, max, 5, max, max, max], [max, max, max, 50, max, max], [max, max, max, max, max, 10], [max, max, max, 20, max, 60], [max, max, max, max, max, max], ] result=dijkstra(graph,0,max) print(\u0026#34;æœ€çŸ­è·¯å¾„çš„å‰é©±èŠ‚ç‚¹æ•°ç»„ä¸ºï¼š\u0026#34;,result) target_index = 5 path_to_target = get_path(result, 0, target_index) print(f\u0026#34;ä»èµ·ç‚¹åˆ°ç›®æ ‡èŠ‚ç‚¹ {target_index} çš„è·¯å¾„ä¸ºï¼š\u0026#34;, path_to_target) ","date":"2025-04-13T14:44:25+08:00","image":"https://example.com/p/dijkstra%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%8F%8Apython%E5%AE%9E%E7%8E%B0/index_hu_edd18e5053fe4098.png","permalink":"https://example.com/p/dijkstra%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%8F%8Apython%E5%AE%9E%E7%8E%B0/","title":"Dijkstraç®—æ³•åŸç†åŠPythonå®ç°"},{"content":"æ ‡é¢˜ æ ‡é¢˜2 ","date":"2025-04-13T14:44:25+08:00","image":"https://example.com/p/first_test/test_hu_22ab779589b0bb50.png","permalink":"https://example.com/p/first_test/","title":"First_test"},{"content":"æ­£æ–‡æµ‹è¯• è€Œè¿™äº›å¹¶ä¸æ˜¯å®Œå…¨é‡è¦ï¼Œæ›´åŠ é‡è¦çš„é—®é¢˜æ˜¯ï¼Œ å¸¦ç€è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æ¥å®¡è§†ä¸€ä¸‹å­¦ç”Ÿä¼šé€€ä¼šã€‚ æ—¢ç„¶å¦‚ä½•ï¼Œ å¯¹æˆ‘ä¸ªäººè€Œè¨€ï¼Œå­¦ç”Ÿä¼šé€€ä¼šä¸ä»…ä»…æ˜¯ä¸€ä¸ªé‡å¤§çš„äº‹ä»¶ï¼Œè¿˜å¯èƒ½ä¼šæ”¹å˜æˆ‘çš„äººç”Ÿã€‚ æˆ‘ä»¬ä¸å¾—ä¸é¢å¯¹ä¸€ä¸ªéå¸¸å°´å°¬çš„äº‹å®ï¼Œé‚£å°±æ˜¯ï¼Œ å¯æ˜¯ï¼Œå³ä½¿æ˜¯è¿™æ ·ï¼Œå­¦ç”Ÿä¼šé€€ä¼šçš„å‡ºç°ä»ç„¶ä»£è¡¨äº†ä¸€å®šçš„æ„ä¹‰ã€‚ å­¦ç”Ÿä¼šé€€ä¼šï¼Œå‘ç”Ÿäº†ä¼šå¦‚ä½•ï¼Œä¸å‘ç”Ÿåˆä¼šå¦‚ä½•ã€‚ ç»è¿‡ä¸Šè¿°è®¨è®ºï¼Œ ç”Ÿæ´»ä¸­ï¼Œè‹¥å­¦ç”Ÿä¼šé€€ä¼šå‡ºç°äº†ï¼Œæˆ‘ä»¬å°±ä¸å¾—ä¸è€ƒè™‘å®ƒå‡ºç°äº†çš„äº‹å®ã€‚ å­¦ç”Ÿä¼šé€€ä¼šï¼Œåˆ°åº•åº”è¯¥å¦‚ä½•å®ç°ã€‚ è¿™æ ·çœ‹æ¥ï¼Œ åœ¨è¿™ç§å›°éš¾çš„æŠ‰æ‹©ä¸‹ï¼Œæœ¬äººæ€æ¥æƒ³å»ï¼Œå¯é£Ÿéš¾å®‰ã€‚ å¯¹æˆ‘ä¸ªäººè€Œè¨€ï¼Œå­¦ç”Ÿä¼šé€€ä¼šä¸ä»…ä»…æ˜¯ä¸€ä¸ªé‡å¤§çš„äº‹ä»¶ï¼Œè¿˜å¯èƒ½ä¼šæ”¹å˜æˆ‘çš„äººç”Ÿã€‚ å°±æˆ‘ä¸ªäººæ¥è¯´ï¼Œå­¦ç”Ÿä¼šé€€ä¼šå¯¹æˆ‘çš„æ„ä¹‰ï¼Œä¸èƒ½ä¸è¯´éå¸¸é‡å¤§ã€‚ èå£«æ¯”äºšæ›¾ç»æåˆ°è¿‡ï¼Œäººçš„ä¸€ç”Ÿæ˜¯çŸ­çš„ï¼Œä½†å¦‚æœå‘åŠ£åœ°è¿‡è¿™ä¸€ç”Ÿï¼Œå°±å¤ªé•¿äº†ã€‚è¿™ä¼¼ä¹è§£ç­”äº†æˆ‘çš„ç–‘æƒ‘ã€‚ è«æ‰ç‰¹è¯´è¿‡ä¸€å¥å¯Œæœ‰å“²ç†çš„è¯ï¼Œè°å’Œæˆ‘ä¸€æ ·ç”¨åŠŸï¼Œè°å°±ä¼šå’Œæˆ‘ä¸€æ ·æˆåŠŸã€‚è¿™å¯å‘äº†æˆ‘ï¼Œ å¯¹æˆ‘ä¸ªäººè€Œè¨€ï¼Œå­¦ç”Ÿä¼šé€€ä¼šä¸ä»…ä»…æ˜¯ä¸€ä¸ªé‡å¤§çš„äº‹ä»¶ï¼Œè¿˜å¯èƒ½ä¼šæ”¹å˜æˆ‘çš„äººç”Ÿã€‚ å­¦ç”Ÿä¼šé€€ä¼šï¼Œåˆ°åº•åº”è¯¥å¦‚ä½•å®ç°ã€‚ ä¸€èˆ¬æ¥è¯´ï¼Œ ä»è¿™ä¸ªè§’åº¦æ¥çœ‹ï¼Œ è¿™ç§äº‹å®å¯¹æœ¬äººæ¥è¯´æ„ä¹‰é‡å¤§ï¼Œç›¸ä¿¡å¯¹è¿™ä¸ªä¸–ç•Œä¹Ÿæ˜¯æœ‰ä¸€å®šæ„ä¹‰çš„ã€‚ åœ¨è¿™ç§å›°éš¾çš„æŠ‰æ‹©ä¸‹ï¼Œæœ¬äººæ€æ¥æƒ³å»ï¼Œå¯é£Ÿéš¾å®‰ã€‚ äº†è§£æ¸…æ¥šå­¦ç”Ÿä¼šé€€ä¼šåˆ°åº•æ˜¯ä¸€ç§æ€ä¹ˆæ ·çš„å­˜åœ¨ï¼Œæ˜¯è§£å†³ä¸€åˆ‡é—®é¢˜çš„å…³é”®ã€‚ ä¸€èˆ¬æ¥è¯´ï¼Œ ç”Ÿæ´»ä¸­ï¼Œè‹¥å­¦ç”Ÿä¼šé€€ä¼šå‡ºç°äº†ï¼Œæˆ‘ä»¬å°±ä¸å¾—ä¸è€ƒè™‘å®ƒå‡ºç°äº†çš„äº‹å®ã€‚ é—®é¢˜çš„å…³é”®ç©¶ç«Ÿä¸ºä½•ï¼Ÿ è€Œè¿™äº›å¹¶ä¸æ˜¯å®Œå…¨é‡è¦ï¼Œæ›´åŠ é‡è¦çš„é—®é¢˜æ˜¯ã€‚\nå¥¥æ–¯ç‰¹æ´›å¤«æ–¯åŸºæ›¾ç»è¯´è¿‡ï¼Œå…±åŒçš„äº‹ä¸šï¼Œå…±åŒçš„æ–—äº‰ï¼Œå¯ä»¥ä½¿äººä»¬äº§ç”Ÿå¿å—ä¸€åˆ‡çš„åŠ›é‡ã€‚ã€€å¸¦ç€è¿™å¥è¯ï¼Œæˆ‘ä»¬è¿˜è¦æ›´åŠ æ…é‡çš„å®¡è§†è¿™ä¸ªé—®é¢˜ï¼š ä¸€èˆ¬æ¥è®²ï¼Œæˆ‘ä»¬éƒ½å¿…é¡»åŠ¡å¿…æ…é‡çš„è€ƒè™‘è€ƒè™‘ã€‚ æ—¢ç„¶å¦‚æ­¤ï¼Œ è¿™ç§äº‹å®å¯¹æœ¬äººæ¥è¯´æ„ä¹‰é‡å¤§ï¼Œç›¸ä¿¡å¯¹è¿™ä¸ªä¸–ç•Œä¹Ÿæ˜¯æœ‰ä¸€å®šæ„ä¹‰çš„ã€‚ å¸¦ç€è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æ¥å®¡è§†ä¸€ä¸‹å­¦ç”Ÿä¼šé€€ä¼šã€‚ æˆ‘è®¤ä¸ºï¼Œ æˆ‘è®¤ä¸ºï¼Œ åœ¨è¿™ç§å›°éš¾çš„æŠ‰æ‹©ä¸‹ï¼Œæœ¬äººæ€æ¥æƒ³å»ï¼Œå¯é£Ÿéš¾å®‰ã€‚ é—®é¢˜çš„å…³é”®ç©¶ç«Ÿä¸ºä½•ï¼Ÿ æ¯ä¸ªäººéƒ½ä¸å¾—ä¸é¢å¯¹è¿™äº›é—®é¢˜ã€‚ åœ¨é¢å¯¹è¿™ç§é—®é¢˜æ—¶ï¼Œ è¦æƒ³æ¸…æ¥šï¼Œå­¦ç”Ÿä¼šé€€ä¼šï¼Œåˆ°åº•æ˜¯ä¸€ç§æ€ä¹ˆæ ·çš„å­˜åœ¨ã€‚ æˆ‘è®¤ä¸ºï¼Œ æ—¢ç„¶å¦‚æ­¤ï¼Œ æ¯ä¸ªäººéƒ½ä¸å¾—ä¸é¢å¯¹è¿™äº›é—®é¢˜ã€‚ åœ¨é¢å¯¹è¿™ç§é—®é¢˜æ—¶ï¼Œ é‚£ä¹ˆï¼Œ æˆ‘è®¤ä¸ºï¼Œ å­¦ç”Ÿä¼šé€€ä¼šå› ä½•è€Œå‘ç”Ÿã€‚\nå¼•ç”¨ æ€å¿µæ˜¯æœ€æš–çš„å¿§ä¼¤åƒä¸€åŒç¿…è†€\nè®©æˆ‘åœä¸äº†é£ä¸è¿œåœ¨è¿‡å¾€æ¸¸è¡\nä¸å‘Šè€Œåˆ«çš„ä½  å°±ç®—ä¸ºäº†æˆ‘ç€æƒ³\nè¿™ä¹ˆæ²‰ç—›çš„å‘µæŠ¤ æˆ‘æ€ä¹ˆèƒ½ç¿±ç¿”\næœ€æš–çš„æ†‚å‚· - ç”°é¦¥ç”„\nå›¾ç‰‡ 1 2 3 ![Photo by Florian Klauer on Unsplash](florian-klauer-nptLmg6jqDo-unsplash.jpg) ![Photo by Luca Bravo on Unsplash](luca-bravo-alS7ewQ41M8-unsplash.jpg) ![Photo by Helena Hertz on Unsplash](helena-hertz-wWZzXlDpMog-unsplash.jpg) ![Photo by Hudai Gayiran on Unsplash](hudai-gayiran-3Od_VKcDEAA-unsplash.jpg) ç›¸å†Œè¯­æ³•æ¥è‡ª Typlog\n","date":"2020-09-09T00:00:00Z","image":"https://example.com/p/test-chinese/helena-hertz-wWZzXlDpMog-unsplash_hu_2307260c751d0e0b.jpg","permalink":"https://example.com/p/test-chinese/","title":"Chinese Test"}]